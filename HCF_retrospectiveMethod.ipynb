{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute HCF variables not only at 12z as we were doing in HCF.ipynb, but also for 18z, 21z, and 00z. This enables us to use the retrospective method for determining if CI was triggered locally or not. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import comet as cm \n",
    "import numpy as np \n",
    "import xarray as xr \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import datetime \n",
    "import time \n",
    "from ComputeHCF import HCF \n",
    "from joblib import Parallel, delayed \n",
    "import multiprocess as mp\n",
    "import itertools\n",
    "\n",
    "# Plotting utils \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as colors\n",
    "import cartopy\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with all the data saved in it...\n",
    "dataDir = '/glade/work/mdfowler/data/HighOutput_IslasSims/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Read in data for CAM6 + CLM5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  app.launch_new_instance()\n",
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with reading in files for year 1980\n",
      "Done with reading in files for year 1981\n",
      "Done with reading in files for year 1982\n"
     ]
    }
   ],
   "source": [
    "# Set up strings used to define/access each file \n",
    "fileStart  = 'f.e21.FHIST.f09_f09.cesm2_cam6_clm5.001.cam.h4.'\n",
    "profileEnd = '_conusAllTimes-VertProfiles.nc'\n",
    "pressEnd   = '_conus-Pressure-UTCtimes.nc'\n",
    "\n",
    "years = np.arange(1980,1983).astype(str)\n",
    "\n",
    "# Read in yearly files \n",
    "for iYr in range(len(years)): \n",
    "    # Set up file names \n",
    "    fileName_profile = dataDir+fileStart+years[iYr]+profileEnd\n",
    "    fileName_press   = dataDir+fileStart+years[iYr]+pressEnd\n",
    "    \n",
    "    # Open files and save to larger arrays \n",
    "    with xr.open_dataset(fileName_profile, decode_times=True) as profileDS:\n",
    "        profileDS['time'] = profileDS.indexes['time'].to_datetimeindex()\n",
    "        profileDS\n",
    "        \n",
    "        if iYr==0:\n",
    "            fullDS_profiles = profileDS\n",
    "        else: \n",
    "            fullDS_profiles = xr.concat([fullDS_profiles, profileDS], dim='time')\n",
    "\n",
    "            \n",
    "    with xr.open_dataset(fileName_press, decode_times=True) as pressDS:\n",
    "        pressDS['time'] = pressDS.indexes['time'].to_datetimeindex()\n",
    "        \n",
    "        if iYr==0:\n",
    "            fullDS_pressure = pressDS\n",
    "        else: \n",
    "            fullDS_pressure = xr.concat([fullDS_pressure,pressDS], dim='time')\n",
    "    \n",
    "    print('Done with reading in files for year %s' % years[iYr])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_CLM5 = fullDS_profiles\n",
    "ds_CLM5['PRESSURE'] = (('time','lev','lat','lon'), fullDS_pressure.PRESSURE)\n",
    "ds_CLM5['UTC_hr'] = (('time'), fullDS_pressure.UTC_hr)\n",
    "ds_CLM5['UTC_day'] = (('time'), fullDS_pressure.UTC_day)\n",
    "ds_CLM5['UTC_mon'] = (('time'), fullDS_pressure.UTC_mon)\n",
    "ds_CLM5['UTC_yr'] = (('time'), fullDS_pressure.UTC_yr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Read in data for CAM6 + CLM4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:27: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with reading in files for year 1980\n",
      "Done with reading in files for year 1981\n",
      "Done with reading in files for year 1982\n"
     ]
    }
   ],
   "source": [
    "# Set up strings used to define/access each file \n",
    "fileStart  = 'f.e21.FHIST.f09_f09.cesm2_cam6_clm4p5.001.cam.h4.'\n",
    "profileEnd = '_conusAllTimes-VertProfiles.nc'\n",
    "pressEnd   = '_conus-Pressure-UTCtimes.nc'\n",
    "\n",
    "years = np.arange(1980,1983).astype(str)\n",
    "\n",
    "\n",
    "# Read in yearly files \n",
    "for iYr in range(len(years)): \n",
    "    # Set up file names \n",
    "    fileName_profile = dataDir+fileStart+years[iYr]+profileEnd\n",
    "    fileName_press   = dataDir+fileStart+years[iYr]+pressEnd\n",
    "    \n",
    "    # Open files and save to larger arrays \n",
    "    with xr.open_dataset(fileName_profile, decode_times=True) as profileDS:\n",
    "        profileDS['time'] = profileDS.indexes['time'].to_datetimeindex()\n",
    "        profileDS\n",
    "        \n",
    "        if iYr==0:\n",
    "            fullDS_profiles = profileDS\n",
    "        else: \n",
    "            fullDS_profiles = xr.concat([fullDS_profiles, profileDS], dim='time')\n",
    "\n",
    "            \n",
    "    with xr.open_dataset(fileName_press, decode_times=True) as pressDS:\n",
    "        pressDS['time'] = pressDS.indexes['time'].to_datetimeindex()\n",
    "        \n",
    "        if iYr==0:\n",
    "            fullDS_pressure = pressDS\n",
    "        else: \n",
    "            fullDS_pressure = xr.concat([fullDS_pressure,pressDS], dim='time')\n",
    "    \n",
    "    print('Done with reading in files for year %s' % years[iYr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_CLM45 = fullDS_profiles\n",
    "ds_CLM45['PRESSURE'] = (('time','lev','lat','lon'), fullDS_pressure.PRESSURE)\n",
    "ds_CLM45['UTC_hr'] = (('time'), fullDS_pressure.UTC_hr)\n",
    "ds_CLM45['UTC_day'] = (('time'), fullDS_pressure.UTC_day)\n",
    "ds_CLM45['UTC_mon'] = (('time'), fullDS_pressure.UTC_mon)\n",
    "ds_CLM45['UTC_yr'] = (('time'), fullDS_pressure.UTC_yr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Isolate 18z, 21z, and 00z into their own datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...18Z isolated...\n"
     ]
    }
   ],
   "source": [
    "# Pick out 18Z \n",
    "ds_utc18_CLM45 = ds_CLM45.where( ds_CLM45.UTC_hr==18.0, drop=True )\n",
    "#ds_utc18_CLM5  = ds_CLM5.where(  ds_CLM5.UTC_hr==18.0,  drop=True )\n",
    "print('...18Z isolated...')\n",
    "\n",
    "# # Pick out 21Z \n",
    "# ds_utc21_CLM45 = ds_CLM45.where( ds_CLM45.UTC_hr==21.0, drop=True )\n",
    "# ds_utc21_CLM5  = ds_CLM5.where(  ds_CLM5.UTC_hr==21.0,  drop=True )\n",
    "# print('...21Z isolated...')\n",
    "\n",
    "# # Pick out 00Z \n",
    "# ds_utc00_CLM45 = ds_CLM45.where( ds_CLM45.UTC_hr==0.0, drop=True )\n",
    "# ds_utc00_CLM5  = ds_CLM5.where(  ds_CLM5.UTC_hr==0.0,  drop=True )\n",
    "# print('...00Z isolated...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of days:  1095\n"
     ]
    }
   ],
   "source": [
    "# Also get lat and lon\n",
    "lat = ds_utc18_CLM45.lat.values\n",
    "lon = ds_utc18_CLM45.lon.values \n",
    "\n",
    "# Number of times (same for all...)\n",
    "nTime = len(ds_utc18_CLM45.time.values)\n",
    "print('Numer of days: ', nTime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute HCF and save variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_HCF_parallel(DS, iT):\n",
    "    \n",
    "    # Define variable names \n",
    "    Tname = 'T'\n",
    "    Qname = 'Q'\n",
    "    Zname = 'Z3'\n",
    "    Pname = 'PRESSURE'\n",
    "\n",
    "    TBM_all     = np.full([len(lat),len(lon)], np.nan)\n",
    "    BCLH_all    = np.full([len(lat),len(lon)], np.nan)\n",
    "    BCLP_all    = np.full([len(lat),len(lon)], np.nan)\n",
    "    TDEF_all    = np.full([len(lat),len(lon)], np.nan)\n",
    "    TRAN_H_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "    TRAN_P_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "    TRAN_T_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "    SHDEF_M_all = np.full([len(lat),len(lon)], np.nan)\n",
    "    LHDEF_M_all = np.full([len(lat),len(lon)], np.nan)\n",
    "    EADV_M_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "\n",
    "\n",
    "    DS = DS.drop('time_bnds')  # Want to get rid of nbnd dimension \n",
    "\n",
    "    # Want to also drop ilev dimension\n",
    "    DS = DS.drop('hyai')\n",
    "    DS = DS.drop('hybi') \n",
    "    DS = DS.drop('ilev')\n",
    "    \n",
    "    # Number of levels to worry about in actual \"sounding\"\n",
    "    nLev  = len(DS.lev)\n",
    "    \n",
    "    for iLat in range(len(lat)):\n",
    "        for iLon in range(len(lon)): \n",
    "            # Pick out specific point and time period \n",
    "            DF  = DS.isel(lat=iLat,lon=iLon,time=iT).to_dataframe()\n",
    "\n",
    "            # Flip order of levels so that surface comes first (required for function)\n",
    "            DF = DF.reindex(index=DF.index[::-1])\n",
    "\n",
    "            TBM_all[iLat,iLon],BCLH_all[iLat,iLon],BCLP_all[iLat,iLon],TDEF_all[iLat,iLon],TRAN_H_all[iLat,iLon],TRAN_P_all[iLat,iLon],TRAN_T_all[iLat,iLon],SHDEF_M_all[iLat,iLon],LHDEF_M_all[iLat,iLon], EADV_M_all[iLat,iLon] = HCF(DF, \n",
    "                                                                              Tname, \n",
    "                                                                              Qname, \n",
    "                                                                              Zname, \n",
    "                                                                              Pname, \n",
    "                                                                              nLev) \n",
    "    \n",
    "    # print('Done with day %i of 1095  ...' % (iT) )\n",
    "    \n",
    "    return TBM_all,BCLH_all,BCLP_all,TDEF_all,TRAN_H_all,TRAN_P_all,TRAN_T_all,SHDEF_M_all,LHDEF_M_all,EADV_M_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out timing of using parallel nJobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:550: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask         = np.where((~np.isnan(xaxis1)) & (xaxis1>pthresh))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:583: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask         = np.where((~np.isnan(xaxis1)) & (xaxis1>pthresh))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:588: RuntimeWarning: invalid value encountered in less_equal\n",
      "  if ( (np.all(xaxis1<=pthresh)) & (np.all(xaxis>=pbl_p)) & (np.all(np.isnan(xaxis1))) ):\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:592: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask       = np.where( (xaxis1>pthresh) & (xaxis<pbl_p) & (~np.isnan(xaxis1)))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:692: RuntimeWarning: invalid value encountered in less\n",
      "  if ( (np.all(np.isnan(eadv))) | (np.all(eadv<45)) | (np.all(np.isnan(eadv))) | (np.all(eadv>45)) ):\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:692: RuntimeWarning: invalid value encountered in greater\n",
      "  if ( (np.all(np.isnan(eadv))) | (np.all(eadv<45)) | (np.all(np.isnan(eadv))) | (np.all(eadv>45)) ):\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:710: RuntimeWarning: invalid value encountered in less_equal\n",
      "  iMask    = np.where((eadv_0<=0) & (~np.isnan(eadv_0)))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:718: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask    = np.where((eadv_0>0) & (~np.isnan(eadv_0)))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For loop took 304.3860 sec\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ds_utc18_CLM5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m                 \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/u/apps/dav/opt/python/3.7.5/gnu/8.3.0/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-185e5f8792e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mstartParr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtestResult2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_HCF_parallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_utc18_CLM5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miT\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mstart2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mTBM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBCLH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBCLP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTDEF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRANH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRANP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRANT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSHDEFM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLHDEFM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEADVM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtestResult2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0mislice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-185e5f8792e1>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mstartParr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtestResult2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_HCF_parallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_utc18_CLM5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miT\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mstart2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mTBM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBCLH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBCLP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTDEF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRANH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRANP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTRANT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSHDEFM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLHDEFM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEADVM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtestResult2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds_utc18_CLM5' is not defined"
     ]
    }
   ],
   "source": [
    "# Start out with just a for loop as a kind of \"control\"\n",
    "start = time.time()\n",
    "testResult = np.full([20,10,len(lat),len(lon)], np.nan)\n",
    "for iT in range(20):\n",
    "    testResult[iT,:,:,:] = my_HCF_parallel(ds_utc18_CLM45, iT)\n",
    "end = time.time()\n",
    "print('For loop took %.4f sec' %(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 2 threads, time to compute results: 296.1083\n",
      "Time to unzip: 0.0002\n",
      "Total time for parralelized: 296.1086\n"
     ]
    }
   ],
   "source": [
    "# n_jobs =2 \n",
    "startParr   = time.time()\n",
    "testResult2 = Parallel(n_jobs=2)(delayed(my_HCF_parallel)(ds_utc18_CLM45,iT) for iT in range(20))\n",
    "start2      = time.time()\n",
    "TBM,BCLH,BCLP,TDEF,TRANH,TRANP,TRANT,SHDEFM,LHDEFM,EADVM = zip(*testResult2)\n",
    "endParr     = time.time()\n",
    "print('With 2 threads, time to compute results: %.4f' %(start2-startParr))\n",
    "print('Time to unzip: %.4f' %(endParr-start2))\n",
    "print('Total time for parralelized: %.4f' %(endParr-startParr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 5 threads, time to compute results: 313.8495\n",
      "Time to unzip: 0.0008\n",
      "Total time for parralelized: 313.8503\n"
     ]
    }
   ],
   "source": [
    "# n_jobs = 5\n",
    "startParr   = time.time()\n",
    "testResult2 = Parallel(n_jobs=5)(delayed(my_HCF_parallel)(ds_utc18_CLM45,iT) for iT in range(20))\n",
    "start2      = time.time()\n",
    "TBM,BCLH,BCLP,TDEF,TRANH,TRANP,TRANT,SHDEFM,LHDEFM,EADVM = zip(*testResult2)\n",
    "endParr     = time.time()\n",
    "print('With 5 threads, time to compute results: %.4f' %(start2-startParr))\n",
    "print('Time to unzip: %.4f' %(endParr-start2))\n",
    "print('Total time for parralelized: %.4f' %(endParr-startParr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:550: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask         = np.where((~np.isnan(xaxis1)) & (xaxis1>pthresh))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:583: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask         = np.where((~np.isnan(xaxis1)) & (xaxis1>pthresh))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:588: RuntimeWarning: invalid value encountered in less_equal\n",
      "  if ( (np.all(xaxis1<=pthresh)) & (np.all(xaxis>=pbl_p)) & (np.all(np.isnan(xaxis1))) ):\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:592: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask       = np.where( (xaxis1>pthresh) & (xaxis<pbl_p) & (~np.isnan(xaxis1)))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:692: RuntimeWarning: invalid value encountered in less\n",
      "  if ( (np.all(np.isnan(eadv))) | (np.all(eadv<45)) | (np.all(np.isnan(eadv))) | (np.all(eadv>45)) ):\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:692: RuntimeWarning: invalid value encountered in greater\n",
      "  if ( (np.all(np.isnan(eadv))) | (np.all(eadv<45)) | (np.all(np.isnan(eadv))) | (np.all(eadv>45)) ):\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:710: RuntimeWarning: invalid value encountered in less_equal\n",
      "  iMask    = np.where((eadv_0<=0) & (~np.isnan(eadv_0)))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:718: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask    = np.where((eadv_0>0) & (~np.isnan(eadv_0)))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With -2 threads, time to compute results: 339.7693\n",
      "Time to unzip: 0.0010\n",
      "Total time for parralelized: 339.7703\n"
     ]
    }
   ],
   "source": [
    "# n_jobs = -2 \n",
    "startParr = time.time()\n",
    "testResult2 = Parallel(n_jobs=-2)(delayed(my_HCF_parallel)(ds_utc18_CLM45,iT) for iT in range(20))\n",
    "start2 = time.time()\n",
    "TBM,BCLH,BCLP,TDEF,TRANH,TRANP,TRANT,SHDEFM,LHDEFM,EADVM = zip(*testResult2)\n",
    "endParr = time.time()\n",
    "print('With -2 threads, time to compute results: %.4f' %(start2-startParr))\n",
    "print('Time to unzip: %.4f' %(endParr-start2))\n",
    "print('Total time for parralelized: %.4f' %(endParr-startParr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 10 threads, time to compute results: 346.0705\n",
      "Time to unzip: 0.0147\n",
      "Total time for parralelized: 346.0853\n"
     ]
    }
   ],
   "source": [
    "# n_jobs = 10\n",
    "startParr = time.time()\n",
    "testResult2 = Parallel(n_jobs=10)(delayed(my_HCF_parallel)(ds_utc18_CLM45,iT) for iT in range(20))\n",
    "start2 = time.time()\n",
    "TBM,BCLH,BCLP,TDEF,TRANH,TRANP,TRANT,SHDEFM,LHDEFM,EADVM = zip(*testResult2)\n",
    "endParr = time.time()\n",
    "print('With 10 threads, time to compute results: %.4f' %(start2-startParr))\n",
    "print('Time to unzip: %.4f' %(endParr-start2))\n",
    "print('Total time for parralelized: %.4f' %(endParr-startParr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 10 threads, time to compute results: 333.0381\n",
      "Time to unzip: 0.0002\n",
      "Total time for parralelized: 333.0383\n"
     ]
    }
   ],
   "source": [
    "# n_jobs = 20\n",
    "startParr = time.time()\n",
    "testResult2 = Parallel(n_jobs=20)(delayed(my_HCF_parallel)(ds_utc18_CLM45,iT) for iT in range(20))\n",
    "start2 = time.time()\n",
    "TBM,BCLH,BCLP,TDEF,TRANH,TRANP,TRANT,SHDEFM,LHDEFM,EADVM = zip(*testResult2)\n",
    "endParr = time.time()\n",
    "print('With 10 threads, time to compute results: %.4f' %(start2-startParr))\n",
    "print('Time to unzip: %.4f' %(endParr-start2))\n",
    "print('Total time for parralelized: %.4f' %(endParr-startParr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>What if I only have it return one variable of interest at a time? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_HCF_parallelTest(DS, iT,iLat,iLon):\n",
    "    \n",
    "    # Define variable names \n",
    "    Tname = 'T'\n",
    "    Qname = 'Q'\n",
    "    Zname = 'Z3'\n",
    "    Pname = 'PRESSURE'\n",
    "\n",
    "#     TBM_all     = np.full([len(lat),len(lon)], np.nan)\n",
    "#     BCLH_all    = np.full([len(lat),len(lon)], np.nan)\n",
    "#     BCLP_all    = np.full([len(lat),len(lon)], np.nan)\n",
    "#     TDEF_all    = np.full([len(lat),len(lon)], np.nan)\n",
    "#     TRAN_H_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "#     TRAN_P_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "#     TRAN_T_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "#     SHDEF_M_all = np.full([len(lat),len(lon)], np.nan)\n",
    "#     LHDEF_M_all = np.full([len(lat),len(lon)], np.nan)\n",
    "#     EADV_M_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "\n",
    "    DS = DS.drop('time_bnds')  # Want to get rid of nbnd dimension \n",
    "\n",
    "    # Want to also drop ilev dimension\n",
    "    DS = DS.drop('hyai')\n",
    "    DS = DS.drop('hybi') \n",
    "    DS = DS.drop('ilev')\n",
    "    \n",
    "    # Number of levels to worry about in actual \"sounding\"\n",
    "    nLev  = len(DS.lev)\n",
    "    \n",
    "#     for iLat in range(len(lat)):\n",
    "#         for iLon in range(len(lon)): \n",
    "#             # Pick out specific point and time period \n",
    "    DF  = DS.isel(lat=iLat,lon=iLon,time=iT).to_dataframe()\n",
    "\n",
    "    # Flip order of levels so that surface comes first (required for function)\n",
    "    DF = DF.reindex(index=DF.index[::-1])\n",
    "\n",
    "    TBM_all,BCLH_all,BCLP_all,TDEF_all,TRAN_H_all,TRAN_P_all,TRAN_T_all,SHDEF_M_all,LHDEF_M_all,EADV_M_al = HCF(DF, \n",
    "                                                                      Tname, \n",
    "                                                                      Qname, \n",
    "                                                                      Zname, \n",
    "                                                                      Pname, \n",
    "                                                                      nLev) \n",
    "    \n",
    "    # print('Done with day %i of 1095  ...' % (iT) )\n",
    "    \n",
    "    return TDEF_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 5 threads, time to compute results: 303.2731\n",
      "Time to unzip: 0.0001\n",
      "Total time for parralelized: 303.2731\n"
     ]
    }
   ],
   "source": [
    "# n_jobs = 5 -- had modified function to return just TDEF_ALL, but do all lat/lon in one go\n",
    "#   But that made no difference in timing...\n",
    "startParr   = time.time()\n",
    "testResult2 = Parallel(n_jobs=5)(delayed(my_HCF_parallelTest)(ds_utc18_CLM45,iT) for iT in range(20))\n",
    "start2      = time.time()\n",
    "endParr     = time.time()\n",
    "print('With 5 threads, time to compute results: %.4f' %(start2-startParr))\n",
    "print('Time to unzip: %.4f' %(endParr-start2))\n",
    "print('Total time for parralelized: %.4f' %(endParr-startParr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [0,20,40] =  47.0075215786992\n"
     ]
    }
   ],
   "source": [
    "print('Before: [0,20,40] = ', np.asarray(testResult2)[0,20,40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for parralelized, 5 threads: 457.8225\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'testResults2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-efd93d43b41f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestResultLots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtestReshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestResultLots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Before: [0,20,40] = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestResults2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Now:    [0,20,40] = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestReshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testResults2' is not defined"
     ]
    }
   ],
   "source": [
    "# This uses a test version of script that took in all the indices rather than relying on for loops, \n",
    "#   and only returns one variable to make life a bit easier. \n",
    "# But this has also had no real impact on timing... if anything it's the worst! \n",
    "# \n",
    "# n_jobs = 5\n",
    "startParr      = time.time()\n",
    "testResultLots = Parallel(n_jobs=5)(delayed(my_HCF_parallelTest)(ds_utc18_CLM45,iT,iLat,iLon) for iT in range(20) for iLat in range(len(lat)) for iLon in range(len(lon)))\n",
    "endParr        = time.time()\n",
    "print('Total time for parralelized, 5 threads: %.4f' %(endParr-startParr))\n",
    "\n",
    "np.shape(testResultLots)\n",
    "testReshape = np.asarray(testResultLots).reshape([20,len(lat),len(lon)])\n",
    "\n",
    "# Error message no longer relevant; worked out in below cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [0,20,40] =  31.144030054987184\n",
      "Now:    [0,20,40] =  [31.14403005]\n"
     ]
    }
   ],
   "source": [
    "print('Before: [0,20,40] = ', np.asarray(testResult2)[10,20,40])\n",
    "print('Now:    [0,20,40] = ', testReshape[10,20,40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check that parallel *does* speed things up in a very simple test, taken from online: https://medium.com/@measurespace/use-joblib-to-run-your-python-code-in-parallel-ad82abb26954 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0305 s\n",
      "15.0300 s\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "def my_fun_2p(i, j):\n",
    "    \"\"\" We define a simple function with two parameters.\n",
    "    \"\"\"\n",
    "    time.sleep(1)\n",
    "    return math.sqrt(i**j)\n",
    "\n",
    "j_num = 3\n",
    "num = 10\n",
    "start = time.time()\n",
    "for i in range(num):\n",
    "    for j in range(j_num):\n",
    "        my_fun_2p(i, j)\n",
    "end = time.time()\n",
    "print('{:.4f} s'.format(end-start))\n",
    "\n",
    "start = time.time()\n",
    "# n_jobs is the number of parallel jobs\n",
    "Parallel(n_jobs=2)(delayed(my_fun_2p)(i, j) for i in range(num) for j in range(j_num))\n",
    "end = time.time()\n",
    "print('{:.4f} s'.format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2906 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# n_jobs is the number of parallel jobs\n",
    "Parallel(n_jobs=3)(delayed(my_fun_2p)(i, j) for i in range(num) for j in range(j_num))\n",
    "end = time.time()\n",
    "print('{:.4f} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This part is known to work at least...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute for 18Z, CLM5: \n",
    "result_18z = Parallel(n_jobs=5)(delayed(my_HCF_parallel)(ds_utc18_CLM5,iT) for iT in range(nTime))\n",
    "TBM_18z,BCLH_18z,BCLP_18z,TDEF_18z,TRANH_18z,TRANP_18z,TRANT_18z,SHDEFM_18z,LHDEFM_18z,EADVM_18z = zip(*result_18z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved!\n",
      "  /glade/work/mdfowler/scripts/Coupling_CAM6CLM5/processed_data/HCFvariables-CAM6CLM5-18z_1980-1982.nc\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Create xr dataset from variables above \n",
    "# ---------------------------------------\n",
    "\n",
    "# First set missing values to -9999\n",
    "missingValue  = -9999\n",
    "\n",
    "TBM_write     = np.copy(TBM_18z)\n",
    "BCLH_write    = np.copy(BCLH_18z)\n",
    "BCLP_write    = np.copy(BCLP_18z)\n",
    "TDEF_write    = np.copy(TDEF_18z)\n",
    "TRAN_H_write  = np.copy(TRANH_18z)\n",
    "TRAN_P_write  = np.copy(TRANP_18z)\n",
    "TRAN_T_write  = np.copy(TRANT_18z)\n",
    "SHDEF_M_write = np.copy(SHDEFM_18z)\n",
    "LHDEF_M_write = np.copy(LHDEFM_18z)\n",
    "EADV_M_write  = np.copy(EADVM_18z)\n",
    "\n",
    "TBM_write    [np.isnan(TBM_18z)   ==True] = missingValue\n",
    "BCLH_write   [np.isnan(BCLH_18z)  ==True] = missingValue\n",
    "BCLP_write   [np.isnan(BCLP_18z)  ==True] = missingValue\n",
    "TDEF_write   [np.isnan(TDEF_18z)  ==True] = missingValue\n",
    "TRAN_H_write [np.isnan(TRANH_18z) ==True] = missingValue\n",
    "TRAN_P_write [np.isnan(TRANP_18z) ==True] = missingValue\n",
    "TRAN_T_write [np.isnan(TRANT_18z) ==True] = missingValue\n",
    "SHDEF_M_write[np.isnan(SHDEFM_18z)==True] = missingValue\n",
    "LHDEF_M_write[np.isnan(LHDEFM_18z)==True] = missingValue\n",
    "EADV_M_write [np.isnan(EADVM_18z) ==True] = missingValue\n",
    " \n",
    "HCF_ds = xr.Dataset({\n",
    "    'TBM': xr.DataArray(\n",
    "                data   = TBM_write,   # enter data here\n",
    "                dims   = ['time','lat','lon'],\n",
    "                coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "                attrs  = {\n",
    "                    '_FillValue': missingValue,\n",
    "                    'units'     : 'K',\n",
    "                    'LongName'  : 'Buoyant mixing potential temperature (convective threshold)'\n",
    "                    }\n",
    "                ),\n",
    "    'BCLH': xr.DataArray(\n",
    "                data   = BCLH_write,   # enter data here\n",
    "                dims   = ['time','lat','lon'],\n",
    "                coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "                attrs  = {\n",
    "                    '_FillValue': missingValue,\n",
    "                    'units'     : 'm',\n",
    "                    'LongName'  : 'Height above ground of convective threshold'\n",
    "                    }\n",
    "                ),\n",
    "    'BCLP': xr.DataArray(\n",
    "            data   = BCLP_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'Pa',\n",
    "                'LongName'  : 'Pressure of convective threshold'\n",
    "                }\n",
    "            ),\n",
    "    'TDEF': xr.DataArray(\n",
    "            data   = TDEF_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'K',\n",
    "                'LongName'  : 'Potential temperature deficit needed to initiate convection'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_H': xr.DataArray(\n",
    "            data   = TRAN_H_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'm',\n",
    "                'LongName'  : 'Energy transition height'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_P': xr.DataArray(\n",
    "            data   = TRAN_P_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'Pa',\n",
    "                'LongName'  : 'Energy transition pressure'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_T': xr.DataArray(\n",
    "            data   = TRAN_T_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'K',\n",
    "                'LongName'  : 'Energy transition temperature'\n",
    "                }\n",
    "            ),\n",
    "    'SHDEF_M': xr.DataArray(\n",
    "            data   = SHDEF_M_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'J/m2',\n",
    "                'LongName'  : 'Sensible heat deficit of mixed layer'\n",
    "                }\n",
    "            ),\n",
    "    'LHDEF_M': xr.DataArray(\n",
    "            data   = LHDEF_M_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'J/m2',\n",
    "                'LongName'  : 'Latent heat deficit of mixed layer'\n",
    "                }\n",
    "            ),\n",
    "    'EADV_M': xr.DataArray(\n",
    "            data   = EADV_M_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : '-',\n",
    "                'LongName'  : 'Energy advantage of mixed layer'\n",
    "                }\n",
    "            )\n",
    "    } )\n",
    "\n",
    "# -------------------\n",
    "# Save to netCDF \n",
    "# -------------------\n",
    "\n",
    "savePath = '/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/processed_data/HCFvariables-CAM6CLM5-18z_1980-1982.nc'\n",
    "HCF_ds.to_netcdf(savePath, mode='w')\n",
    "print('File saved!\\n ', savePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Clear 18z, CLM5 variables from memory: \n",
    "#   Not sure if you can just list them with del...\n",
    "# ---------------------------------------\n",
    "\n",
    "del result_18z \n",
    "del TBM_18z\n",
    "del BCLH_18z\n",
    "del BCLP_18z\n",
    "del TDEF_18z, \n",
    "del TRANH_18z\n",
    "del TRANP_18z\n",
    "del TRANT_18z\n",
    "del SHDEFM_18z\n",
    "del LHDEFM_18z\n",
    "del EADVM_18z \n",
    "del TBM_write    \n",
    "del BCLH_write  \n",
    "del BCLP_write  \n",
    "del TDEF_write  \n",
    "del TRAN_H_write\n",
    "del TRAN_P_write  \n",
    "del TRAN_T_write \n",
    "del SHDEF_M_write \n",
    "del LHDEF_M_write \n",
    "del EADV_M_write  \n",
    "del HCF_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute for 21Z, CLM5: \n",
    "result_21z = Parallel(n_jobs=5)(delayed(my_HCF_parallel)(ds_utc21_CLM5,iT) for iT in range(nTime))\n",
    "TBM_21z,BCLH_21z,BCLP_21z,TDEF_21z,TRANH_21z,TRANP_21z,TRANT_21z,SHDEFM_21z,LHDEFM_21z,EADVM_21z = zip(*result_21z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
