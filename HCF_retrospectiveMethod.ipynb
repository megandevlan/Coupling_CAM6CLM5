{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute HCF variables not only at 12z as we were doing in HCF.ipynb, but also for 18z, 21z, and 00z. This enables us to use the retrospective method for determining if CI was triggered locally or not. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import comet as cm \n",
    "import numpy as np \n",
    "import xarray as xr \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import datetime \n",
    "import time \n",
    "from ComputeHCF import HCF \n",
    "from joblib import Parallel, delayed \n",
    "\n",
    "# Plotting utils \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as colors\n",
    "import cartopy\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Read in data for CAM6 + CLM5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-72071a3316c3>:18: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  profileDS['time'] = profileDS.indexes['time'].to_datetimeindex()\n",
      "<ipython-input-3-72071a3316c3>:28: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  pressDS['time'] = pressDS.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with reading in files for year 1980\n",
      "Done with reading in files for year 1981\n",
      "Done with reading in files for year 1982\n"
     ]
    }
   ],
   "source": [
    "# Set up strings used to define/access each file \n",
    "dataDir    = '/Users/mdfowler/Documents/Analysis/Coupling_initial/data/3hrSim_CAM6-CLM5/'\n",
    "\n",
    "fileStart  = 'f.e21.FHIST.f09_f09.cesm2_cam6_clm5.001.cam.h4.'\n",
    "profileEnd = '_conusAllTimes-VertProfiles.nc'\n",
    "pressEnd   = '_conus-Pressure-UTCtimes.nc'\n",
    "\n",
    "years = np.arange(1980,1983).astype(str)\n",
    "\n",
    "# Read in yearly files \n",
    "for iYr in range(len(years)): \n",
    "    # Set up file names \n",
    "    fileName_profile = dataDir+fileStart+years[iYr]+profileEnd\n",
    "    fileName_press   = dataDir+fileStart+years[iYr]+pressEnd\n",
    "    \n",
    "    # Open files and save to larger arrays \n",
    "    with xr.open_dataset(fileName_profile, decode_times=True) as profileDS:\n",
    "        profileDS['time'] = profileDS.indexes['time'].to_datetimeindex()\n",
    "        profileDS\n",
    "        \n",
    "        if iYr==0:\n",
    "            fullDS_profiles = profileDS\n",
    "        else: \n",
    "            fullDS_profiles = xr.concat([fullDS_profiles, profileDS], dim='time')\n",
    "\n",
    "            \n",
    "    with xr.open_dataset(fileName_press, decode_times=True) as pressDS:\n",
    "        pressDS['time'] = pressDS.indexes['time'].to_datetimeindex()\n",
    "        \n",
    "        if iYr==0:\n",
    "            fullDS_pressure = pressDS\n",
    "        else: \n",
    "            fullDS_pressure = xr.concat([fullDS_pressure,pressDS], dim='time')\n",
    "    \n",
    "    print('Done with reading in files for year %s' % years[iYr])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_CLM5 = fullDS_profiles\n",
    "ds_CLM5['PRESSURE'] = (('time','lev','lat','lon'), fullDS_pressure.PRESSURE)\n",
    "ds_CLM5['UTC_hr'] = (('time'), fullDS_pressure.UTC_hr)\n",
    "ds_CLM5['UTC_day'] = (('time'), fullDS_pressure.UTC_day)\n",
    "ds_CLM5['UTC_mon'] = (('time'), fullDS_pressure.UTC_mon)\n",
    "ds_CLM5['UTC_yr'] = (('time'), fullDS_pressure.UTC_yr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Read in data for CAM6 + CLM4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-269b4c824156>:19: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  profileDS['time'] = profileDS.indexes['time'].to_datetimeindex()\n",
      "<ipython-input-5-269b4c824156>:29: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  pressDS['time'] = pressDS.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with reading in files for year 1980\n",
      "Done with reading in files for year 1981\n",
      "Done with reading in files for year 1982\n"
     ]
    }
   ],
   "source": [
    "# Set up strings used to define/access each file \n",
    "dataDir    = '/Users/mdfowler/Documents/Analysis/Coupling_initial/data/3hrSim_CAM6-CLM45/'\n",
    "\n",
    "fileStart  = 'f.e21.FHIST.f09_f09.cesm2_cam6_clm4p5.001.cam.h4.'\n",
    "profileEnd = '_conusAllTimes-VertProfiles.nc'\n",
    "pressEnd   = '_conus-Pressure-UTCtimes.nc'\n",
    "\n",
    "years = np.arange(1980,1983).astype(str)\n",
    "\n",
    "\n",
    "# Read in yearly files \n",
    "for iYr in range(len(years)): \n",
    "    # Set up file names \n",
    "    fileName_profile = dataDir+fileStart+years[iYr]+profileEnd\n",
    "    fileName_press   = dataDir+fileStart+years[iYr]+pressEnd\n",
    "    \n",
    "    # Open files and save to larger arrays \n",
    "    with xr.open_dataset(fileName_profile, decode_times=True) as profileDS:\n",
    "        profileDS['time'] = profileDS.indexes['time'].to_datetimeindex()\n",
    "        profileDS\n",
    "        \n",
    "        if iYr==0:\n",
    "            fullDS_profiles = profileDS\n",
    "        else: \n",
    "            fullDS_profiles = xr.concat([fullDS_profiles, profileDS], dim='time')\n",
    "\n",
    "            \n",
    "    with xr.open_dataset(fileName_press, decode_times=True) as pressDS:\n",
    "        pressDS['time'] = pressDS.indexes['time'].to_datetimeindex()\n",
    "        \n",
    "        if iYr==0:\n",
    "            fullDS_pressure = pressDS\n",
    "        else: \n",
    "            fullDS_pressure = xr.concat([fullDS_pressure,pressDS], dim='time')\n",
    "    \n",
    "    print('Done with reading in files for year %s' % years[iYr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_CLM45 = fullDS_profiles\n",
    "ds_CLM45['PRESSURE'] = (('time','lev','lat','lon'), fullDS_pressure.PRESSURE)\n",
    "ds_CLM45['UTC_hr'] = (('time'), fullDS_pressure.UTC_hr)\n",
    "ds_CLM45['UTC_day'] = (('time'), fullDS_pressure.UTC_day)\n",
    "ds_CLM45['UTC_mon'] = (('time'), fullDS_pressure.UTC_mon)\n",
    "ds_CLM45['UTC_yr'] = (('time'), fullDS_pressure.UTC_yr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Isolate 18z, 21z, and 00z into their own datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18Z isolated\n",
      "21Z isolated\n",
      "00Z isolated\n"
     ]
    }
   ],
   "source": [
    "# Pick out 18Z \n",
    "ds_utc18_CLM45 = ds_CLM45.where( ds_CLM45.UTC_hr==18.0, drop=True )\n",
    "ds_utc18_CLM5  = ds_CLM5.where(  ds_CLM5.UTC_hr==18.0,  drop=True )\n",
    "print('18Z isolated')\n",
    "\n",
    "# Pick out 21Z \n",
    "ds_utc21_CLM45 = ds_CLM45.where( ds_CLM45.UTC_hr==21.0, drop=True )\n",
    "ds_utc21_CLM5  = ds_CLM5.where(  ds_CLM5.UTC_hr==21.0,  drop=True )\n",
    "print('21Z isolated')\n",
    "\n",
    "# Pick out 00Z \n",
    "ds_utc00_CLM45 = ds_CLM45.where( ds_CLM45.UTC_hr==0.0, drop=True )\n",
    "ds_utc00_CLM5  = ds_CLM5.where(  ds_CLM5.UTC_hr==0.0,  drop=True )\n",
    "print('00Z isolated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also get lat and lon\n",
    "lat = ds_utc18_CLM45.lat.values\n",
    "lon = ds_utc18_CLM45.lon.values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute HCF and save variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_HCF_parallel(iT):\n",
    "    \n",
    "    # Define variable names \n",
    "    Tname = 'T'\n",
    "    Qname = 'Q'\n",
    "    Zname = 'Z3'\n",
    "    Pname = 'PRESSURE'\n",
    "\n",
    "    TBM_all     = np.full([len(lat),len(lon)], np.nan)\n",
    "    BCLH_all    = np.full([len(lat),len(lon)], np.nan)\n",
    "    BCLP_all    = np.full([len(lat),len(lon)], np.nan)\n",
    "    TDEF_all    = np.full([len(lat),len(lon)], np.nan)\n",
    "    TRAN_H_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "    TRAN_P_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "    TRAN_T_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "    SHDEF_M_all = np.full([len(lat),len(lon)], np.nan)\n",
    "    LHDEF_M_all = np.full([len(lat),len(lon)], np.nan)\n",
    "    EADV_M_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "\n",
    "\n",
    "    # -------------------------------------\n",
    "    #  NOTE: This section SHOULD BE MODIFIED \n",
    "    #        to change which model version/\n",
    "    #        hour is desired \n",
    "    # -------------------------------------\n",
    "    ds_interest = ds_utc18_CLM45\n",
    "    ds_interest = ds_interest.drop('time_bnds')  # Want to get rid of nbnd dimension \n",
    "\n",
    "    # Want to also drop ilev dimension\n",
    "    ds_interest = ds_interest.drop('hyai')\n",
    "    ds_interest = ds_interest.drop('hybi') \n",
    "    ds_interest = ds_interest.drop('ilev')\n",
    "    \n",
    "    # Number of levels to worry about in actual \"sounding\"\n",
    "    nLev  = len(ds_interest.lev)\n",
    "\n",
    "    \n",
    "    for iLat in range(len(lat)):\n",
    "        for iLon in range(len(lon)): \n",
    "            # Pick out specific point and time period \n",
    "            DF  = ds_interest.isel(lat=iLat,lon=iLon,time=iT).to_dataframe()\n",
    "\n",
    "            # Flip order of levels so that surface comes first (required for function)\n",
    "            DF = DF.reindex(index=DF.index[::-1])\n",
    "\n",
    "            TBM_all[iLat,iLon],BCLH_all[iLat,iLon],BCLP_all[iLat,iLon],TDEF_all[iLat,iLon],TRAN_H_all[iLat,iLon],TRAN_P_all[iLat,iLon],TRAN_T_all[iLat,iLon],SHDEF_M_all[iLat,iLon],LHDEF_M_all[iLat,iLon], EADV_M_all[iLat,iLon] = HCF(DF, \n",
    "                                                                              Tname, \n",
    "                                                                              Qname, \n",
    "                                                                              Zname, \n",
    "                                                                              Pname, \n",
    "                                                                              nLev) \n",
    "    \n",
    "    return TBM_all,BCLH_all,BCLP_all,TDEF_all,TRAN_H_all,TRAN_P_all,TRAN_T_all,SHDEF_M_all,LHDEF_M_all,EADV_M_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r1 = Parallel(n_jobs=2)(delayed(my_HCF_parallel)(iT) for iT in range(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10, 43, 65)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBM,BCLH,BCLP,TDEF,TRANH,TRANP,TRANT,SHDEFM,LHDEFM,EADVM = zip(*r1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 43, 65)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(TBM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
