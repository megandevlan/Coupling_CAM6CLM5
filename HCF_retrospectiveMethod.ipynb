{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute HCF variables not only at 12z as we were doing in HCF.ipynb, but also for 18z, 21z, and 00z. This enables us to use the retrospective method for determining if CI was triggered locally or not. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import comet as cm \n",
    "import numpy as np \n",
    "import xarray as xr \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import datetime \n",
    "import time \n",
    "from ComputeHCF import HCF \n",
    "from joblib import Parallel, delayed \n",
    "\n",
    "# Plotting utils \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as colors\n",
    "import cartopy\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with all the data saved in it...\n",
    "dataDir = '/glade/work/mdfowler/data/HighOutput_IslasSims/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Read in data for CAM6 + CLM5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  app.launch_new_instance()\n",
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with reading in files for year 1980\n",
      "Done with reading in files for year 1981\n",
      "Done with reading in files for year 1982\n"
     ]
    }
   ],
   "source": [
    "# Set up strings used to define/access each file \n",
    "fileStart  = 'f.e21.FHIST.f09_f09.cesm2_cam6_clm5.001.cam.h4.'\n",
    "profileEnd = '_conusAllTimes-VertProfiles.nc'\n",
    "pressEnd   = '_conus-Pressure-UTCtimes.nc'\n",
    "\n",
    "years = np.arange(1980,1983).astype(str)\n",
    "\n",
    "# Read in yearly files \n",
    "for iYr in range(len(years)): \n",
    "    # Set up file names \n",
    "    fileName_profile = dataDir+fileStart+years[iYr]+profileEnd\n",
    "    fileName_press   = dataDir+fileStart+years[iYr]+pressEnd\n",
    "    \n",
    "    # Open files and save to larger arrays \n",
    "    with xr.open_dataset(fileName_profile, decode_times=True) as profileDS:\n",
    "        profileDS['time'] = profileDS.indexes['time'].to_datetimeindex()\n",
    "        profileDS\n",
    "        \n",
    "        if iYr==0:\n",
    "            fullDS_profiles = profileDS\n",
    "        else: \n",
    "            fullDS_profiles = xr.concat([fullDS_profiles, profileDS], dim='time')\n",
    "\n",
    "            \n",
    "    with xr.open_dataset(fileName_press, decode_times=True) as pressDS:\n",
    "        pressDS['time'] = pressDS.indexes['time'].to_datetimeindex()\n",
    "        \n",
    "        if iYr==0:\n",
    "            fullDS_pressure = pressDS\n",
    "        else: \n",
    "            fullDS_pressure = xr.concat([fullDS_pressure,pressDS], dim='time')\n",
    "    \n",
    "    print('Done with reading in files for year %s' % years[iYr])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_CLM5 = fullDS_profiles\n",
    "ds_CLM5['PRESSURE'] = (('time','lev','lat','lon'), fullDS_pressure.PRESSURE)\n",
    "ds_CLM5['UTC_hr'] = (('time'), fullDS_pressure.UTC_hr)\n",
    "ds_CLM5['UTC_day'] = (('time'), fullDS_pressure.UTC_day)\n",
    "ds_CLM5['UTC_mon'] = (('time'), fullDS_pressure.UTC_mon)\n",
    "ds_CLM5['UTC_yr'] = (('time'), fullDS_pressure.UTC_yr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Read in data for CAM6 + CLM4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:27: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with reading in files for year 1980\n",
      "Done with reading in files for year 1981\n",
      "Done with reading in files for year 1982\n"
     ]
    }
   ],
   "source": [
    "# Set up strings used to define/access each file \n",
    "fileStart  = 'f.e21.FHIST.f09_f09.cesm2_cam6_clm4p5.001.cam.h4.'\n",
    "profileEnd = '_conusAllTimes-VertProfiles.nc'\n",
    "pressEnd   = '_conus-Pressure-UTCtimes.nc'\n",
    "\n",
    "years = np.arange(1980,1983).astype(str)\n",
    "\n",
    "\n",
    "# Read in yearly files \n",
    "for iYr in range(len(years)): \n",
    "    # Set up file names \n",
    "    fileName_profile = dataDir+fileStart+years[iYr]+profileEnd\n",
    "    fileName_press   = dataDir+fileStart+years[iYr]+pressEnd\n",
    "    \n",
    "    # Open files and save to larger arrays \n",
    "    with xr.open_dataset(fileName_profile, decode_times=True) as profileDS:\n",
    "        profileDS['time'] = profileDS.indexes['time'].to_datetimeindex()\n",
    "        profileDS\n",
    "        \n",
    "        if iYr==0:\n",
    "            fullDS_profiles = profileDS\n",
    "        else: \n",
    "            fullDS_profiles = xr.concat([fullDS_profiles, profileDS], dim='time')\n",
    "\n",
    "            \n",
    "    with xr.open_dataset(fileName_press, decode_times=True) as pressDS:\n",
    "        pressDS['time'] = pressDS.indexes['time'].to_datetimeindex()\n",
    "        \n",
    "        if iYr==0:\n",
    "            fullDS_pressure = pressDS\n",
    "        else: \n",
    "            fullDS_pressure = xr.concat([fullDS_pressure,pressDS], dim='time')\n",
    "    \n",
    "    print('Done with reading in files for year %s' % years[iYr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_CLM45 = fullDS_profiles\n",
    "ds_CLM45['PRESSURE'] = (('time','lev','lat','lon'), fullDS_pressure.PRESSURE)\n",
    "ds_CLM45['UTC_hr'] = (('time'), fullDS_pressure.UTC_hr)\n",
    "ds_CLM45['UTC_day'] = (('time'), fullDS_pressure.UTC_day)\n",
    "ds_CLM45['UTC_mon'] = (('time'), fullDS_pressure.UTC_mon)\n",
    "ds_CLM45['UTC_yr'] = (('time'), fullDS_pressure.UTC_yr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Isolate 18z, 21z, and 00z into their own datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...18Z isolated...\n",
      "...21Z isolated...\n",
      "...00Z isolated...\n"
     ]
    }
   ],
   "source": [
    "# Pick out 18Z \n",
    "ds_utc18_CLM45 = ds_CLM45.where( ds_CLM45.UTC_hr==18.0, drop=True )\n",
    "ds_utc18_CLM5  = ds_CLM5.where(  ds_CLM5.UTC_hr==18.0,  drop=True )\n",
    "print('...18Z isolated...')\n",
    "\n",
    "# Pick out 21Z \n",
    "ds_utc21_CLM45 = ds_CLM45.where( ds_CLM45.UTC_hr==21.0, drop=True )\n",
    "ds_utc21_CLM5  = ds_CLM5.where(  ds_CLM5.UTC_hr==21.0,  drop=True )\n",
    "print('...21Z isolated...')\n",
    "\n",
    "# Pick out 00Z \n",
    "ds_utc00_CLM45 = ds_CLM45.where( ds_CLM45.UTC_hr==0.0, drop=True )\n",
    "ds_utc00_CLM5  = ds_CLM5.where(  ds_CLM5.UTC_hr==0.0,  drop=True )\n",
    "print('...00Z isolated...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of days:  1095\n"
     ]
    }
   ],
   "source": [
    "# Also get lat and lon\n",
    "lat = ds_utc18_CLM45.lat.values\n",
    "lon = ds_utc18_CLM45.lon.values \n",
    "\n",
    "# Number of times (same for all...)\n",
    "nTime = len(ds_utc18_CLM45.time.values)\n",
    "print('Numer of days: ', nTime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute HCF and save variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_HCF_parallel(DS, iT):\n",
    "    \n",
    "    # Define variable names \n",
    "    Tname = 'T'\n",
    "    Qname = 'Q'\n",
    "    Zname = 'Z3'\n",
    "    Pname = 'PRESSURE'\n",
    "\n",
    "    TBM_all     = np.full([len(lat),len(lon)], np.nan)\n",
    "    BCLH_all    = np.full([len(lat),len(lon)], np.nan)\n",
    "    BCLP_all    = np.full([len(lat),len(lon)], np.nan)\n",
    "    TDEF_all    = np.full([len(lat),len(lon)], np.nan)\n",
    "    TRAN_H_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "    TRAN_P_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "    TRAN_T_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "    SHDEF_M_all = np.full([len(lat),len(lon)], np.nan)\n",
    "    LHDEF_M_all = np.full([len(lat),len(lon)], np.nan)\n",
    "    EADV_M_all  = np.full([len(lat),len(lon)], np.nan)\n",
    "\n",
    "\n",
    "    DS = DS.drop('time_bnds')  # Want to get rid of nbnd dimension \n",
    "\n",
    "    # Want to also drop ilev dimension\n",
    "    DS = DS.drop('hyai')\n",
    "    DS = DS.drop('hybi') \n",
    "    DS = DS.drop('ilev')\n",
    "    \n",
    "    # Number of levels to worry about in actual \"sounding\"\n",
    "    nLev  = len(DS.lev)\n",
    "    \n",
    "    for iLat in range(len(lat)):\n",
    "        for iLon in range(len(lon)): \n",
    "            # Pick out specific point and time period \n",
    "            DF  = DS.isel(lat=iLat,lon=iLon,time=iT).to_dataframe()\n",
    "\n",
    "            # Flip order of levels so that surface comes first (required for function)\n",
    "            DF = DF.reindex(index=DF.index[::-1])\n",
    "\n",
    "            TBM_all[iLat,iLon],BCLH_all[iLat,iLon],BCLP_all[iLat,iLon],TDEF_all[iLat,iLon],TRAN_H_all[iLat,iLon],TRAN_P_all[iLat,iLon],TRAN_T_all[iLat,iLon],SHDEF_M_all[iLat,iLon],LHDEF_M_all[iLat,iLon], EADV_M_all[iLat,iLon] = HCF(DF, \n",
    "                                                                              Tname, \n",
    "                                                                              Qname, \n",
    "                                                                              Zname, \n",
    "                                                                              Pname, \n",
    "                                                                              nLev) \n",
    "    \n",
    "    # print('Done with day %i of 1095  ...' % (iT) )\n",
    "    \n",
    "    return TBM_all,BCLH_all,BCLP_all,TDEF_all,TRAN_H_all,TRAN_P_all,TRAN_T_all,SHDEF_M_all,LHDEF_M_all,EADV_M_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute for 18Z, CLM5: \n",
    "result_18z = Parallel(n_jobs=5)(delayed(my_HCF_parallel)(ds_utc18_CLM5,iT) for iT in range(nTime))\n",
    "TBM_18z,BCLH_18z,BCLP_18z,TDEF_18z,TRANH_18z,TRANP_18z,TRANT_18z,SHDEFM_18z,LHDEFM_18z,EADVM_18z = zip(*result_18z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved!\n",
      "  /glade/work/mdfowler/scripts/Coupling_CAM6CLM5/processed_data/HCFvariables-CAM6CLM5-18z_1980-1982.nc\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Create xr dataset from variables above \n",
    "# ---------------------------------------\n",
    "\n",
    "# First set missing values to -9999\n",
    "missingValue  = -9999\n",
    "\n",
    "TBM_write     = np.copy(TBM_18z)\n",
    "BCLH_write    = np.copy(BCLH_18z)\n",
    "BCLP_write    = np.copy(BCLP_18z)\n",
    "TDEF_write    = np.copy(TDEF_18z)\n",
    "TRAN_H_write  = np.copy(TRANH_18z)\n",
    "TRAN_P_write  = np.copy(TRANP_18z)\n",
    "TRAN_T_write  = np.copy(TRANT_18z)\n",
    "SHDEF_M_write = np.copy(SHDEFM_18z)\n",
    "LHDEF_M_write = np.copy(LHDEFM_18z)\n",
    "EADV_M_write  = np.copy(EADVM_18z)\n",
    "\n",
    "TBM_write    [np.isnan(TBM_18z)   ==True] = missingValue\n",
    "BCLH_write   [np.isnan(BCLH_18z)  ==True] = missingValue\n",
    "BCLP_write   [np.isnan(BCLP_18z)  ==True] = missingValue\n",
    "TDEF_write   [np.isnan(TDEF_18z)  ==True] = missingValue\n",
    "TRAN_H_write [np.isnan(TRANH_18z) ==True] = missingValue\n",
    "TRAN_P_write [np.isnan(TRANP_18z) ==True] = missingValue\n",
    "TRAN_T_write [np.isnan(TRANT_18z) ==True] = missingValue\n",
    "SHDEF_M_write[np.isnan(SHDEFM_18z)==True] = missingValue\n",
    "LHDEF_M_write[np.isnan(LHDEFM_18z)==True] = missingValue\n",
    "EADV_M_write [np.isnan(EADVM_18z) ==True] = missingValue\n",
    " \n",
    "HCF_ds = xr.Dataset({\n",
    "    'TBM': xr.DataArray(\n",
    "                data   = TBM_write,   # enter data here\n",
    "                dims   = ['time','lat','lon'],\n",
    "                coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "                attrs  = {\n",
    "                    '_FillValue': missingValue,\n",
    "                    'units'     : 'K',\n",
    "                    'LongName'  : 'Buoyant mixing potential temperature (convective threshold)'\n",
    "                    }\n",
    "                ),\n",
    "    'BCLH': xr.DataArray(\n",
    "                data   = BCLH_write,   # enter data here\n",
    "                dims   = ['time','lat','lon'],\n",
    "                coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "                attrs  = {\n",
    "                    '_FillValue': missingValue,\n",
    "                    'units'     : 'm',\n",
    "                    'LongName'  : 'Height above ground of convective threshold'\n",
    "                    }\n",
    "                ),\n",
    "    'BCLP': xr.DataArray(\n",
    "            data   = BCLP_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'Pa',\n",
    "                'LongName'  : 'Pressure of convective threshold'\n",
    "                }\n",
    "            ),\n",
    "    'TDEF': xr.DataArray(\n",
    "            data   = TDEF_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'K',\n",
    "                'LongName'  : 'Potential temperature deficit needed to initiate convection'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_H': xr.DataArray(\n",
    "            data   = TRAN_H_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'm',\n",
    "                'LongName'  : 'Energy transition height'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_P': xr.DataArray(\n",
    "            data   = TRAN_P_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'Pa',\n",
    "                'LongName'  : 'Energy transition pressure'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_T': xr.DataArray(\n",
    "            data   = TRAN_T_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'K',\n",
    "                'LongName'  : 'Energy transition temperature'\n",
    "                }\n",
    "            ),\n",
    "    'SHDEF_M': xr.DataArray(\n",
    "            data   = SHDEF_M_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'J/m2',\n",
    "                'LongName'  : 'Sensible heat deficit of mixed layer'\n",
    "                }\n",
    "            ),\n",
    "    'LHDEF_M': xr.DataArray(\n",
    "            data   = LHDEF_M_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'J/m2',\n",
    "                'LongName'  : 'Latent heat deficit of mixed layer'\n",
    "                }\n",
    "            ),\n",
    "    'EADV_M': xr.DataArray(\n",
    "            data   = EADV_M_write,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc18_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : '-',\n",
    "                'LongName'  : 'Energy advantage of mixed layer'\n",
    "                }\n",
    "            )\n",
    "    } )\n",
    "\n",
    "# -------------------\n",
    "# Save to netCDF \n",
    "# -------------------\n",
    "\n",
    "savePath = '/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/processed_data/HCFvariables-CAM6CLM5-18z_1980-1982.nc'\n",
    "HCF_ds.to_netcdf(savePath, mode='w')\n",
    "print('File saved!\\n ', savePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Clear 18z, CLM5 variables from memory: \n",
    "#   Not sure if you can just list them with del...\n",
    "# ---------------------------------------\n",
    "\n",
    "del result_18z \n",
    "del TBM_18z\n",
    "del BCLH_18z\n",
    "del BCLP_18z\n",
    "del TDEF_18z, \n",
    "del TRANH_18z\n",
    "del TRANP_18z\n",
    "del TRANT_18z\n",
    "del SHDEFM_18z\n",
    "del LHDEFM_18z\n",
    "del EADVM_18z \n",
    "del TBM_write    \n",
    "del BCLH_write  \n",
    "del BCLP_write  \n",
    "del TDEF_write  \n",
    "del TRAN_H_write\n",
    "del TRAN_P_write  \n",
    "del TRAN_T_write \n",
    "del SHDEF_M_write \n",
    "del LHDEF_M_write \n",
    "del EADV_M_write  \n",
    "del HCF_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute for 21Z, CLM5: \n",
    "result_21z = Parallel(n_jobs=5)(delayed(my_HCF_parallel)(ds_utc21_CLM5,iT) for iT in range(nTime))\n",
    "TBM_21z,BCLH_21z,BCLP_21z,TDEF_21z,TRANH_21z,TRANP_21z,TRANT_21z,SHDEFM_21z,LHDEFM_21z,EADVM_21z = zip(*result_21z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
