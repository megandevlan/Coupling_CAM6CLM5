{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute HCF by year and safe into new file\n",
    "Built to run on Casper where data is directly, rather than tranferring to local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import comet as cm \n",
    "import numpy as np \n",
    "import xarray as xr \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import datetime \n",
    "import time \n",
    "from ComputeHCF import HCF \n",
    "from joblib import Parallel, delayed \n",
    "\n",
    "# Plotting utils \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as mpatches\n",
    "import cartopy\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What data do we need?</b> <br>\n",
    "Vertical profiles of: temperature (T), specific humidity (Q), geopotential height (zg in CESM2, Z3 in other runs), and pressure (P). <br>\n",
    "In addition, need lowest level temperature, specfic humidity, height, and pressure - so basically T2m, Q2m, PSfc, and 2m height. <br><br>\n",
    "<b>Units:</b><br>\n",
    "Temperature --> K <br>\n",
    "Height      --> m <br>\n",
    "Sp. Humidity -> kg/kg <br>\n",
    "Pressure    --> Pa  <br><br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearString = '1989'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Read in data for CAM6 + CLM5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with reading in files for year 1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n"
     ]
    }
   ],
   "source": [
    "# Set up strings used to define/access each file \n",
    "dataDir    = '/glade/work/mdfowler/data/HighOutput_IslasSims/'\n",
    "\n",
    "fileStart  = 'f.e21.FHIST.f09_f09.cesm2_cam6_clm5.001.cam.h4.'\n",
    "profileEnd = '_conusAllTimes-VertProfiles.nc'\n",
    "pressEnd   = '_conus-Pressure-UTCtimes.nc'\n",
    "\n",
    "# Set up file names \n",
    "fileName_profile = dataDir+fileStart+yearString+profileEnd\n",
    "fileName_press   = dataDir+fileStart+yearString+pressEnd\n",
    "\n",
    "# Open files and save to larger arrays \n",
    "with xr.open_dataset(fileName_profile, decode_times=True) as fullDS_profiles:\n",
    "    fullDS_profiles['time'] = fullDS_profiles.indexes['time'].to_datetimeindex()\n",
    "\n",
    "with xr.open_dataset(fileName_press, decode_times=True) as fullDS_pressure:\n",
    "    fullDS_pressure['time'] = fullDS_pressure.indexes['time'].to_datetimeindex()\n",
    "\n",
    "print('Done with reading in files for year %s' % yearString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_CLM5 = fullDS_profiles\n",
    "ds_CLM5['PRESSURE'] = (('time','lev','lat','lon'), fullDS_pressure.PRESSURE)\n",
    "ds_CLM5['UTC_hr'] = (('time'), fullDS_pressure.UTC_hr)\n",
    "ds_CLM5['UTC_day'] = (('time'), fullDS_pressure.UTC_day)\n",
    "ds_CLM5['UTC_mon'] = (('time'), fullDS_pressure.UTC_mon)\n",
    "ds_CLM5['UTC_yr'] = (('time'), fullDS_pressure.UTC_yr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out 12 UTC only (early morning for most of US)\n",
    "ds_utc12_CLM5 = ds_CLM5.where( ds_CLM5.UTC_hr==12.0, drop=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out JJA only \n",
    "ds_utc12_CLM5 = ds_utc12_CLM5.where( ds_utc12_CLM5.UTC_mon>=6 , drop=True)\n",
    "ds_utc12_CLM5 = ds_utc12_CLM5.where( ds_utc12_CLM5.UTC_mon<=8 , drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate UTC times \n",
    "UTC_hr_CLM5  = ds_utc12_CLM5.UTC_hr.values\n",
    "UTC_day_CLM5 = ds_utc12_CLM5.UTC_day.values\n",
    "UTC_mon_CLM5 = ds_utc12_CLM5.UTC_mon.values\n",
    "UTC_yr_CLM5  = ds_utc12_CLM5.UTC_yr.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When converting to a dataframe, need to only have relevent dimension included in dataset. Otherwise,\n",
    "#   the function to convert to DF will create extra entries along dimensions that things like temperature and \n",
    "#   humidity don't depend on, breaking the below HCF calculation cell. \n",
    "\n",
    "ds_utc12_CLM5 = ds_utc12_CLM5.drop('time_bnds')  # Want to get rid of nbnd dimension \n",
    "\n",
    "# Want to also drop ilev dimension\n",
    "ds_utc12_CLM5 = ds_utc12_CLM5.drop('hyai')\n",
    "ds_utc12_CLM5 = ds_utc12_CLM5.drop('hybi') \n",
    "ds_utc12_CLM5 = ds_utc12_CLM5.drop('ilev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Read in data for CAM6 + CLM4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with reading in files for year 1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n"
     ]
    }
   ],
   "source": [
    "# Set up strings used to define/access each file \n",
    "dataDir    = '/glade/work/mdfowler/data/HighOutput_IslasSims/'\n",
    "\n",
    "fileStart  = 'f.e21.FHIST.f09_f09.cesm2_cam6_clm4p5.001.cam.h4.'\n",
    "profileEnd = '_conusAllTimes-VertProfiles.nc'\n",
    "pressEnd   = '_conus-Pressure-UTCtimes.nc'\n",
    "\n",
    "# Set up file names \n",
    "fileName_profile = dataDir+fileStart+yearString+profileEnd\n",
    "fileName_press   = dataDir+fileStart+yearString+pressEnd\n",
    "\n",
    "# Open files and save\n",
    "with xr.open_dataset(fileName_profile, decode_times=True) as fullDS_profiles:\n",
    "    fullDS_profiles['time'] = fullDS_profiles.indexes['time'].to_datetimeindex()\n",
    "\n",
    "with xr.open_dataset(fileName_press, decode_times=True) as fullDS_pressure:\n",
    "    fullDS_pressure['time'] = fullDS_pressure.indexes['time'].to_datetimeindex()\n",
    "\n",
    "\n",
    "print('Done with reading in files for year %s' % yearString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_CLM45 = fullDS_profiles\n",
    "ds_CLM45['PRESSURE'] = (('time','lev','lat','lon'), fullDS_pressure.PRESSURE)\n",
    "ds_CLM45['UTC_hr']   = (('time'), fullDS_pressure.UTC_hr)\n",
    "ds_CLM45['UTC_day']  = (('time'), fullDS_pressure.UTC_day)\n",
    "ds_CLM45['UTC_mon']  = (('time'), fullDS_pressure.UTC_mon)\n",
    "ds_CLM45['UTC_yr']   = (('time'), fullDS_pressure.UTC_yr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out 12 UTC only (early morning for most of US)\n",
    "ds_utc12_CLM45 = ds_CLM45.where( ds_CLM45.UTC_hr==12.0, drop=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out JJA only \n",
    "ds_utc12_CLM45 = ds_utc12_CLM45.where( ds_utc12_CLM45.UTC_mon>=6 , drop=True)\n",
    "ds_utc12_CLM45 = ds_utc12_CLM45.where( ds_utc12_CLM45.UTC_mon<=8 , drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate UTC times \n",
    "UTC_hr_CLM45  = ds_utc12_CLM45.UTC_hr.values\n",
    "UTC_day_CLM45 = ds_utc12_CLM45.UTC_day.values\n",
    "UTC_mon_CLM45 = ds_utc12_CLM45.UTC_mon.values\n",
    "UTC_yr_CLM45  = ds_utc12_CLM45.UTC_yr.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also get lat and lon\n",
    "lat = ds_utc12_CLM45.lat.values\n",
    "lon = ds_utc12_CLM45.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When converting to a dataframe, need to only have relevent dimension included in dataset. Otherwise,\n",
    "#   the function to convert to DF will create extra entries along dimensions that things like temperature and \n",
    "#   humidity don't depend on, breaking the below HCF calculation cell. \n",
    "\n",
    "ds_utc12_CLM45 = ds_utc12_CLM45.drop('time_bnds')  # Want to get rid of nbnd dimension \n",
    "\n",
    "# Want to also drop ilev dimension\n",
    "ds_utc12_CLM45 = ds_utc12_CLM45.drop('hyai')\n",
    "ds_utc12_CLM45 = ds_utc12_CLM45.drop('hybi') \n",
    "ds_utc12_CLM45 = ds_utc12_CLM45.drop('ilev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Read in data for CAM5 + CLM5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with reading in files for year 1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/my_npl_clone/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n"
     ]
    }
   ],
   "source": [
    "# Set up strings used to define/access each file \n",
    "dataDir    = '/glade/work/mdfowler/data/CLM5wCAM5_highOutput/'\n",
    "\n",
    "fileStart  = 'f.e21.FHIST.f09_f09_mg17.CLM5wCAM5phys-subDailyOutput.001.cam.h1.'\n",
    "profileEnd = '_conusAllTimes-VertProfiles.nc'\n",
    "pressEnd   = '_conus-Pressure-UTCtimes.nc'\n",
    "\n",
    "# Set up file names \n",
    "fileName_profile = dataDir+fileStart+yearString+profileEnd\n",
    "fileName_press   = dataDir+fileStart+yearString+pressEnd\n",
    "\n",
    "# Open files and save\n",
    "with xr.open_dataset(fileName_profile, decode_times=True) as fullDS_profiles:\n",
    "    fullDS_profiles['time'] = fullDS_profiles.indexes['time'].to_datetimeindex()\n",
    "\n",
    "with xr.open_dataset(fileName_press, decode_times=True) as fullDS_pressure:\n",
    "    fullDS_pressure['time'] = fullDS_pressure.indexes['time'].to_datetimeindex()\n",
    "\n",
    "\n",
    "print('Done with reading in files for year %s' % yearString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_CAM5CLM5 = fullDS_profiles\n",
    "ds_CAM5CLM5['PRESSURE'] = (('time','lev','lat','lon'), fullDS_pressure.PRESSURE)\n",
    "ds_CAM5CLM5['UTC_hr']   = (('time'), fullDS_pressure.UTC_hr)\n",
    "ds_CAM5CLM5['UTC_day']  = (('time'), fullDS_pressure.UTC_day)\n",
    "ds_CAM5CLM5['UTC_mon']  = (('time'), fullDS_pressure.UTC_mon)\n",
    "ds_CAM5CLM5['UTC_yr']   = (('time'), fullDS_pressure.UTC_yr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out 12 UTC only (early morning for most of US)\n",
    "ds_utc12_CAM5CLM5 = ds_CAM5CLM5.where( ds_CAM5CLM5.UTC_hr==12.0, drop=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out JJA only \n",
    "ds_utc12_CAM5CLM5 = ds_utc12_CAM5CLM5.where( ds_utc12_CAM5CLM5.UTC_mon>=6 , drop=True)\n",
    "ds_utc12_CAM5CLM5 = ds_utc12_CAM5CLM5.where( ds_utc12_CAM5CLM5.UTC_mon<=8 , drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate UTC times \n",
    "UTC_hr_CLM45  = ds_utc12_CAM5CLM5.UTC_hr.values\n",
    "UTC_day_CLM45 = ds_utc12_CAM5CLM5.UTC_day.values\n",
    "UTC_mon_CLM45 = ds_utc12_CAM5CLM5.UTC_mon.values\n",
    "UTC_yr_CLM45  = ds_utc12_CAM5CLM5.UTC_yr.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also get lat and lon\n",
    "lat = ds_utc12_CAM5CLM5.lat.values\n",
    "lon = ds_utc12_CAM5CLM5.lon.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When converting to a dataframe, need to only have relevent dimension included in dataset. Otherwise,\n",
    "#   the function to convert to DF will create extra entries along dimensions that things like temperature and \n",
    "#   humidity don't depend on, breaking the below HCF calculation cell. \n",
    "\n",
    "ds_utc12_CAM5CLM5 = ds_utc12_CAM5CLM5.drop('time_bnds')  # Want to get rid of nbnd dimension \n",
    "\n",
    "# Want to also drop ilev dimension\n",
    "ds_utc12_CAM5CLM5 = ds_utc12_CAM5CLM5.drop('hyai')\n",
    "ds_utc12_CAM5CLM5 = ds_utc12_CAM5CLM5.drop('hybi') \n",
    "ds_utc12_CAM5CLM5 = ds_utc12_CAM5CLM5.drop('ilev')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute HCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:550: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask         = np.where((~np.isnan(xaxis1)) & (xaxis1>pthresh))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:583: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask         = np.where((~np.isnan(xaxis1)) & (xaxis1>pthresh))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:588: RuntimeWarning: invalid value encountered in less_equal\n",
      "  if ( (np.all(xaxis1<=pthresh)) & (np.all(xaxis>=pbl_p)) & (np.all(np.isnan(xaxis1))) ):\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:592: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask       = np.where( (xaxis1>pthresh) & (xaxis<pbl_p) & (~np.isnan(xaxis1)))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:692: RuntimeWarning: invalid value encountered in less\n",
      "  if ( (np.all(np.isnan(eadv))) | (np.all(eadv<45)) | (np.all(np.isnan(eadv))) | (np.all(eadv>45)) ):\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:692: RuntimeWarning: invalid value encountered in greater\n",
      "  if ( (np.all(np.isnan(eadv))) | (np.all(eadv<45)) | (np.all(np.isnan(eadv))) | (np.all(eadv>45)) ):\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:710: RuntimeWarning: invalid value encountered in less_equal\n",
      "  iMask    = np.where((eadv_0<=0) & (~np.isnan(eadv_0)))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:718: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask    = np.where((eadv_0>0) & (~np.isnan(eadv_0)))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with lat 0 of 43 \n",
      "Done with lat 1 of 43 \n",
      "Done with lat 2 of 43 \n",
      "Done with lat 3 of 43 \n",
      "Done with lat 4 of 43 \n",
      "Done with lat 5 of 43 \n",
      "Done with lat 6 of 43 \n",
      "Done with lat 7 of 43 \n",
      "Done with lat 8 of 43 \n",
      "Done with lat 9 of 43 \n",
      "Done with lat 10 of 43 \n",
      "Done with lat 11 of 43 \n",
      "Done with lat 12 of 43 \n",
      "Done with lat 13 of 43 \n",
      "Done with lat 14 of 43 \n",
      "Done with lat 15 of 43 \n",
      "Done with lat 16 of 43 \n",
      "Done with lat 17 of 43 \n",
      "Done with lat 18 of 43 \n",
      "Done with lat 19 of 43 \n",
      "Done with lat 20 of 43 \n",
      "Done with lat 21 of 43 \n",
      "Done with lat 22 of 43 \n",
      "Done with lat 23 of 43 \n",
      "Done with lat 24 of 43 \n",
      "Done with lat 25 of 43 \n",
      "Done with lat 26 of 43 \n",
      "Done with lat 27 of 43 \n",
      "Done with lat 28 of 43 \n",
      "Done with lat 29 of 43 \n",
      "Done with lat 30 of 43 \n",
      "Done with lat 31 of 43 \n",
      "Done with lat 32 of 43 \n",
      "Done with lat 33 of 43 \n",
      "Done with lat 34 of 43 \n",
      "Done with lat 35 of 43 \n",
      "Done with lat 36 of 43 \n",
      "Done with lat 37 of 43 \n",
      "Done with lat 38 of 43 \n",
      "Done with lat 39 of 43 \n",
      "Done with lat 40 of 43 \n",
      "Done with lat 41 of 43 \n",
      "Done with lat 42 of 43 \n",
      "Time elapsed for all points and times: 2145.816 sec\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Compute for each day and lat/lon point\n",
    "#   Takes 35-40 minutes to run for one year\n",
    "# ------------------------------------------\n",
    "\n",
    "# Define variable names \n",
    "Tname = 'T'\n",
    "Qname = 'Q'\n",
    "Zname = 'Z3'\n",
    "Pname = 'PRESSURE'\n",
    "\n",
    "# Number of levels to worry about in actual \"sounding\"\n",
    "nLev  = len(ds_utc12_CLM45.lev)\n",
    "\n",
    "# Define dimensions \n",
    "nLat  = len(ds_utc12_CLM45.lat)\n",
    "nLon  = len(ds_utc12_CLM45.lon)\n",
    "nTime = len(ds_utc12_CLM45.time)\n",
    "\n",
    "# Define empty arrays to save things into \n",
    "TBM_CLM45      = np.full([nTime,nLat,nLon], np.nan)\n",
    "BCLH_CLM45     = np.full([nTime,nLat,nLon], np.nan)\n",
    "BCLP_CLM45     = np.full([nTime,nLat,nLon], np.nan)\n",
    "TDEF_CLM45     = np.full([nTime,nLat,nLon], np.nan)\n",
    "TRAN_H_CLM45   = np.full([nTime,nLat,nLon], np.nan)\n",
    "TRAN_P_CLM45   = np.full([nTime,nLat,nLon], np.nan)\n",
    "TRAN_T_CLM45   = np.full([nTime,nLat,nLon], np.nan)\n",
    "SHDEF_M_CLM45  = np.full([nTime,nLat,nLon], np.nan)\n",
    "LHDEF_M_CLM45  = np.full([nTime,nLat,nLon], np.nan)\n",
    "EADV_M_CLM45   = np.full([nTime,nLat,nLon], np.nan)\n",
    "\n",
    "TBM_CLM5       = np.full([nTime,nLat,nLon], np.nan)\n",
    "BCLH_CLM5      = np.full([nTime,nLat,nLon], np.nan)\n",
    "BCLP_CLM5      = np.full([nTime,nLat,nLon], np.nan)\n",
    "TDEF_CLM5      = np.full([nTime,nLat,nLon], np.nan)\n",
    "TRAN_H_CLM5    = np.full([nTime,nLat,nLon], np.nan)\n",
    "TRAN_P_CLM5    = np.full([nTime,nLat,nLon], np.nan)\n",
    "TRAN_T_CLM5    = np.full([nTime,nLat,nLon], np.nan)\n",
    "SHDEF_M_CLM5   = np.full([nTime,nLat,nLon], np.nan)\n",
    "LHDEF_M_CLM5   = np.full([nTime,nLat,nLon], np.nan)\n",
    "EADV_M_CLM5    = np.full([nTime,nLat,nLon], np.nan)\n",
    "\n",
    "# Time how long this takes... \n",
    "t_start     = time.time()\n",
    "\n",
    "for iLat in range(nLat):\n",
    "    for iLon in range(nLon):\n",
    "        for iT in range(nTime):\n",
    "\n",
    "            # Pick out specific point and time period \n",
    "            DF_CLM45 = ds_utc12_CLM45.isel(lat=iLat,lon=iLon,time=iT).to_dataframe()\n",
    "            DF_CLM5  = ds_utc12_CLM5.isel(lat=iLat,lon=iLon,time=iT).to_dataframe()\n",
    "\n",
    "            # Flip order of levels so that surface comes first (required for function)\n",
    "            DF_CLM45 = DF_CLM45.reindex(index=DF_CLM45.index[::-1])\n",
    "            DF_CLM5  = DF_CLM5.reindex(index=DF_CLM5.index[::-1])\n",
    "\n",
    "            # Compute HCF variables - CLM4.5\n",
    "            TBM_CLM45[iT,iLat,iLon],BCLH_CLM45[iT,iLat,iLon],BCLP_CLM45[iT,iLat,iLon],TDEF_CLM45[iT,iLat,iLon],TRAN_H_CLM45[iT,iLat,iLon],TRAN_P_CLM45[iT,iLat,iLon],TRAN_T_CLM45[iT,iLat,iLon],SHDEF_M_CLM45[iT,iLat,iLon],LHDEF_M_CLM45[iT,iLat,iLon], EADV_M_CLM45[iT,iLat,iLon] = HCF(DF_CLM45, \n",
    "                                                                      Tname, \n",
    "                                                                      Qname, \n",
    "                                                                      Zname, \n",
    "                                                                      Pname, \n",
    "                                                                      nLev) \n",
    "\n",
    "            # Compute HCF variables - CLM5\n",
    "            TBM_CLM5[iT,iLat,iLon],BCLH_CLM5[iT,iLat,iLon],BCLP_CLM5[iT,iLat,iLon],TDEF_CLM5[iT,iLat,iLon],TRAN_H_CLM5[iT,iLat,iLon],TRAN_P_CLM5[iT,iLat,iLon],TRAN_T_CLM5[iT,iLat,iLon],SHDEF_M_CLM5[iT,iLat,iLon],LHDEF_M_CLM5[iT,iLat,iLon], EADV_M_CLM5[iT,iLat,iLon] = HCF(DF_CLM5, \n",
    "                                                                      Tname, \n",
    "                                                                      Qname, \n",
    "                                                                      Zname, \n",
    "                                                                      Pname, \n",
    "                                                                      nLev) \n",
    "\n",
    "\n",
    "            \n",
    "    print('Done with lat %i of %i ' % (iLat, nLat))\n",
    "\n",
    "\n",
    "print('Time elapsed for all points and times: %.3f sec' % (time.time() - t_start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Want to run just for CAM5+CLM5 simulation, so setting it seperately here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:550: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask         = np.where((~np.isnan(xaxis1)) & (xaxis1>pthresh))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:583: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask         = np.where((~np.isnan(xaxis1)) & (xaxis1>pthresh))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:588: RuntimeWarning: invalid value encountered in less_equal\n",
      "  if ( (np.all(xaxis1<=pthresh)) & (np.all(xaxis>=pbl_p)) & (np.all(np.isnan(xaxis1))) ):\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:592: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask       = np.where( (xaxis1>pthresh) & (xaxis<pbl_p) & (~np.isnan(xaxis1)))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:692: RuntimeWarning: invalid value encountered in less\n",
      "  if ( (np.all(np.isnan(eadv))) | (np.all(eadv<45)) | (np.all(np.isnan(eadv))) | (np.all(eadv>45)) ):\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:692: RuntimeWarning: invalid value encountered in greater\n",
      "  if ( (np.all(np.isnan(eadv))) | (np.all(eadv<45)) | (np.all(np.isnan(eadv))) | (np.all(eadv>45)) ):\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:710: RuntimeWarning: invalid value encountered in less_equal\n",
      "  iMask    = np.where((eadv_0<=0) & (~np.isnan(eadv_0)))[0]\n",
      "/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/ComputeHCF.py:718: RuntimeWarning: invalid value encountered in greater\n",
      "  iMask    = np.where((eadv_0>0) & (~np.isnan(eadv_0)))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with lat 0 of 43 \n",
      "Done with lat 1 of 43 \n",
      "Done with lat 2 of 43 \n",
      "Done with lat 3 of 43 \n",
      "Done with lat 4 of 43 \n",
      "Done with lat 5 of 43 \n",
      "Done with lat 6 of 43 \n",
      "Done with lat 7 of 43 \n",
      "Done with lat 8 of 43 \n",
      "Done with lat 9 of 43 \n",
      "Done with lat 10 of 43 \n",
      "Done with lat 11 of 43 \n",
      "Done with lat 12 of 43 \n",
      "Done with lat 13 of 43 \n",
      "Done with lat 14 of 43 \n",
      "Done with lat 15 of 43 \n",
      "Done with lat 16 of 43 \n",
      "Done with lat 17 of 43 \n",
      "Done with lat 18 of 43 \n",
      "Done with lat 19 of 43 \n",
      "Done with lat 20 of 43 \n",
      "Done with lat 21 of 43 \n",
      "Done with lat 22 of 43 \n",
      "Done with lat 23 of 43 \n",
      "Done with lat 24 of 43 \n",
      "Done with lat 25 of 43 \n",
      "Done with lat 26 of 43 \n",
      "Done with lat 27 of 43 \n",
      "Done with lat 28 of 43 \n",
      "Done with lat 29 of 43 \n",
      "Done with lat 30 of 43 \n",
      "Done with lat 31 of 43 \n",
      "Done with lat 32 of 43 \n",
      "Done with lat 33 of 43 \n",
      "Done with lat 34 of 43 \n",
      "Done with lat 35 of 43 \n",
      "Done with lat 36 of 43 \n",
      "Done with lat 37 of 43 \n",
      "Done with lat 38 of 43 \n",
      "Done with lat 39 of 43 \n",
      "Done with lat 40 of 43 \n",
      "Done with lat 41 of 43 \n",
      "Done with lat 42 of 43 \n",
      "Time elapsed for all points and times: 906.446 sec\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# Compute for each day and lat/lon point\n",
    "#   Takes 35-40 minutes to run for one year\n",
    "# ------------------------------------------\n",
    "\n",
    "# Define variable names \n",
    "Tname = 'T'\n",
    "Qname = 'Q'\n",
    "Zname = 'Z3'\n",
    "Pname = 'PRESSURE'\n",
    "\n",
    "# Number of levels to worry about in actual \"sounding\"\n",
    "nLev  = len(ds_utc12_CAM5CLM5.lev)\n",
    "\n",
    "# Define dimensions \n",
    "nLat  = len(ds_utc12_CAM5CLM5.lat)\n",
    "nLon  = len(ds_utc12_CAM5CLM5.lon)\n",
    "nTime = len(ds_utc12_CAM5CLM5.time)\n",
    "\n",
    "# Define empty arrays to save things into\n",
    "TBM_CAM5CLM5       = np.full([nTime,nLat,nLon], np.nan)\n",
    "BCLH_CAM5CLM5      = np.full([nTime,nLat,nLon], np.nan)\n",
    "BCLP_CAM5CLM5      = np.full([nTime,nLat,nLon], np.nan)\n",
    "TDEF_CAM5CLM5      = np.full([nTime,nLat,nLon], np.nan)\n",
    "TRAN_H_CAM5CLM5    = np.full([nTime,nLat,nLon], np.nan)\n",
    "TRAN_P_CAM5CLM5    = np.full([nTime,nLat,nLon], np.nan)\n",
    "TRAN_T_CAM5CLM5    = np.full([nTime,nLat,nLon], np.nan)\n",
    "SHDEF_M_CAM5CLM5   = np.full([nTime,nLat,nLon], np.nan)\n",
    "LHDEF_M_CAM5CLM5   = np.full([nTime,nLat,nLon], np.nan)\n",
    "EADV_M_CAM5CLM5    = np.full([nTime,nLat,nLon], np.nan)\n",
    "\n",
    "# Time how long this takes... \n",
    "t_start     = time.time()\n",
    "\n",
    "for iLat in range(nLat):\n",
    "    for iLon in range(nLon):\n",
    "        for iT in range(nTime):\n",
    "\n",
    "            # Pick out specific point and time period \n",
    "            DF_CAM5CLM5  = ds_utc12_CAM5CLM5.isel(lat=iLat,lon=iLon,time=iT).to_dataframe()\n",
    "\n",
    "            # Flip order of levels so that surface comes first (required for function)\n",
    "            DF_CAM5CLM5  = DF_CAM5CLM5.reindex(index=DF_CAM5CLM5.index[::-1])\n",
    "\n",
    "            # Compute HCF variables - CLM5\n",
    "            TBM_CAM5CLM5[iT,iLat,iLon],BCLH_CAM5CLM5[iT,iLat,iLon],BCLP_CAM5CLM5[iT,iLat,iLon],TDEF_CAM5CLM5[iT,iLat,iLon],TRAN_H_CAM5CLM5[iT,iLat,iLon],TRAN_P_CAM5CLM5[iT,iLat,iLon],TRAN_T_CAM5CLM5[iT,iLat,iLon],SHDEF_M_CAM5CLM5[iT,iLat,iLon],LHDEF_M_CAM5CLM5[iT,iLat,iLon], EADV_M_CAM5CLM5[iT,iLat,iLon] = HCF(DF_CAM5CLM5, \n",
    "                                                                      Tname, \n",
    "                                                                      Qname, \n",
    "                                                                      Zname, \n",
    "                                                                      Pname, \n",
    "                                                                      nLev) \n",
    "\n",
    "\n",
    "            \n",
    "    print('Done with lat %i of %i ' % (iLat, nLat))\n",
    "\n",
    "\n",
    "print('Time elapsed for all points and times: %.3f sec' % (time.time() - t_start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create dataset and save to netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file /glade/work/mdfowler/scripts/Coupling_CAM6CLM5/processed_data/HCFvariables-CAM6CLM4p5_1989.nc\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Create xr dataset from variables above \n",
    "# ---------------------------------------\n",
    "\n",
    "# First set missing values to -9999\n",
    "missingValue  = -9999\n",
    "\n",
    "TBM_writeCLM45     = np.copy(TBM_CLM45)\n",
    "BCLH_writeCLM45    = np.copy(BCLH_CLM45)\n",
    "BCLP_writeCLM45    = np.copy(BCLP_CLM45)\n",
    "TDEF_writeCLM45    = np.copy(TDEF_CLM45)\n",
    "TRAN_H_writeCLM45  = np.copy(TRAN_H_CLM45)\n",
    "TRAN_P_writeCLM45  = np.copy(TRAN_P_CLM45)\n",
    "TRAN_T_writeCLM45  = np.copy(TRAN_T_CLM45)\n",
    "SHDEF_M_writeCLM45 = np.copy(SHDEF_M_CLM45)\n",
    "LHDEF_M_writeCLM45 = np.copy(LHDEF_M_CLM45)\n",
    "EADV_M_writeCLM45  = np.copy(EADV_M_CLM45)\n",
    "\n",
    "TBM_writeCLM45    [np.isnan(TBM_CLM45)    ==True] = missingValue\n",
    "BCLH_writeCLM45   [np.isnan(BCLH_CLM45)   ==True] = missingValue\n",
    "BCLP_writeCLM45   [np.isnan(BCLP_CLM45)   ==True] = missingValue\n",
    "TDEF_writeCLM45   [np.isnan(TDEF_CLM45)   ==True] = missingValue\n",
    "TRAN_H_writeCLM45 [np.isnan(TRAN_H_CLM45) ==True] = missingValue\n",
    "TRAN_P_writeCLM45 [np.isnan(TRAN_P_CLM45) ==True] = missingValue\n",
    "TRAN_T_writeCLM45 [np.isnan(TRAN_T_CLM45) ==True] = missingValue\n",
    "SHDEF_M_writeCLM45[np.isnan(SHDEF_M_CLM45)==True] = missingValue\n",
    "LHDEF_M_writeCLM45[np.isnan(LHDEF_M_CLM45)==True] = missingValue\n",
    "EADV_M_writeCLM45 [np.isnan(EADV_M_CLM45) ==True] = missingValue\n",
    " \n",
    "HCF_ds_CLM45 = xr.Dataset({\n",
    "    'TBM': xr.DataArray(\n",
    "                data   = TBM_writeCLM45,   # enter data here\n",
    "                dims   = ['time','lat','lon'],\n",
    "                coords = {'time': ds_utc12_CLM45.time.values, 'lat':lat, 'lon': lon},\n",
    "                attrs  = {\n",
    "                    '_FillValue': missingValue,\n",
    "                    'units'     : 'K',\n",
    "                    'LongName'  : 'Buoyant mixing potential temperature (convective threshold)'\n",
    "                    }\n",
    "                ),\n",
    "    'BCLH': xr.DataArray(\n",
    "                data   = BCLH_writeCLM45,   # enter data here\n",
    "                dims   = ['time','lat','lon'],\n",
    "                coords = {'time': ds_utc12_CLM45.time.values, 'lat':lat, 'lon': lon},\n",
    "                attrs  = {\n",
    "                    '_FillValue': missingValue,\n",
    "                    'units'     : 'm',\n",
    "                    'LongName'  : 'Height above ground of convective threshold'\n",
    "                    }\n",
    "                ),\n",
    "    'BCLP': xr.DataArray(\n",
    "            data   = BCLP_writeCLM45,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM45.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'Pa',\n",
    "                'LongName'  : 'Pressure of convective threshold'\n",
    "                }\n",
    "            ),\n",
    "    'TDEF': xr.DataArray(\n",
    "            data   = TDEF_writeCLM45,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM45.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'K',\n",
    "                'LongName'  : 'Potential temperature deficit needed to initiate convection'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_H': xr.DataArray(\n",
    "            data   = TRAN_H_writeCLM45,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM45.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'm',\n",
    "                'LongName'  : 'Energy transition height'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_P': xr.DataArray(\n",
    "            data   = TRAN_P_writeCLM45,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM45.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'Pa',\n",
    "                'LongName'  : 'Energy transition pressure'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_T': xr.DataArray(\n",
    "            data   = TRAN_T_writeCLM45,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM45.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'K',\n",
    "                'LongName'  : 'Energy transition temperature'\n",
    "                }\n",
    "            ),\n",
    "    'SHDEF_M': xr.DataArray(\n",
    "            data   = SHDEF_M_writeCLM45,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM45.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'J/m2',\n",
    "                'LongName'  : 'Sensible heat deficit of mixed layer'\n",
    "                }\n",
    "            ),\n",
    "    'LHDEF_M': xr.DataArray(\n",
    "            data   = LHDEF_M_writeCLM45,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM45.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'J/m2',\n",
    "                'LongName'  : 'Latent heat deficit of mixed layer'\n",
    "                }\n",
    "            ),\n",
    "    'EADV_M': xr.DataArray(\n",
    "            data   = EADV_M_writeCLM45,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM45.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : '-',\n",
    "                'LongName'  : 'Energy advantage of mixed layer'\n",
    "                }\n",
    "            )\n",
    "    } )\n",
    "\n",
    "# -------------------\n",
    "# Save to netCDF \n",
    "# -------------------\n",
    "\n",
    "savePath = '/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/processed_data/HCFvariables-CAM6CLM4p5_'+yearString+'.nc'\n",
    "HCF_ds_CLM45.to_netcdf(savePath, mode='w')\n",
    "print('Saved file %s' % savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file /glade/work/mdfowler/scripts/Coupling_CAM6CLM5/processed_data/HCFvariables-CAM6CLM5_1989.nc\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Create xr dataset from variables above \n",
    "# ---------------------------------------\n",
    "\n",
    "# First set missing values to -9999\n",
    "missingValue  = -9999\n",
    "\n",
    "TBM_writeCLM5     = np.copy(TBM_CLM5)\n",
    "BCLH_writeCLM5    = np.copy(BCLH_CLM5)\n",
    "BCLP_writeCLM5    = np.copy(BCLP_CLM5)\n",
    "TDEF_writeCLM5    = np.copy(TDEF_CLM5)\n",
    "TRAN_H_writeCLM5  = np.copy(TRAN_H_CLM5)\n",
    "TRAN_P_writeCLM5  = np.copy(TRAN_P_CLM5)\n",
    "TRAN_T_writeCLM5  = np.copy(TRAN_T_CLM5)\n",
    "SHDEF_M_writeCLM5 = np.copy(SHDEF_M_CLM5)\n",
    "LHDEF_M_writeCLM5 = np.copy(LHDEF_M_CLM5)\n",
    "EADV_M_writeCLM5  = np.copy(EADV_M_CLM5)\n",
    "\n",
    "TBM_writeCLM5    [np.isnan(TBM_CLM5)    ==True] = missingValue\n",
    "BCLH_writeCLM5   [np.isnan(BCLH_CLM5)   ==True] = missingValue\n",
    "BCLP_writeCLM5   [np.isnan(BCLP_CLM5)   ==True] = missingValue\n",
    "TDEF_writeCLM5   [np.isnan(TDEF_CLM5)   ==True] = missingValue\n",
    "TRAN_H_writeCLM5 [np.isnan(TRAN_H_CLM5) ==True] = missingValue\n",
    "TRAN_P_writeCLM5 [np.isnan(TRAN_P_CLM5) ==True] = missingValue\n",
    "TRAN_T_writeCLM5 [np.isnan(TRAN_T_CLM5) ==True] = missingValue\n",
    "SHDEF_M_writeCLM5[np.isnan(SHDEF_M_CLM5)==True] = missingValue\n",
    "LHDEF_M_writeCLM5[np.isnan(LHDEF_M_CLM5)==True] = missingValue\n",
    "EADV_M_writeCLM5 [np.isnan(EADV_M_CLM5) ==True] = missingValue\n",
    " \n",
    "HCF_ds_CLM5 = xr.Dataset({\n",
    "    'TBM': xr.DataArray(\n",
    "                data   = TBM_writeCLM5,   # enter data here\n",
    "                dims   = ['time','lat','lon'],\n",
    "                coords = {'time': ds_utc12_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "                attrs  = {\n",
    "                    '_FillValue': missingValue,\n",
    "                    'units'     : 'K',\n",
    "                    'LongName'  : 'Buoyant mixing potential temperature (convective threshold)'\n",
    "                    }\n",
    "                ),\n",
    "    'BCLH': xr.DataArray(\n",
    "                data   = BCLH_writeCLM5,   # enter data here\n",
    "                dims   = ['time','lat','lon'],\n",
    "                coords = {'time': ds_utc12_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "                attrs  = {\n",
    "                    '_FillValue': missingValue,\n",
    "                    'units'     : 'm',\n",
    "                    'LongName'  : 'Height above ground of convective threshold'\n",
    "                    }\n",
    "                ),\n",
    "    'BCLP': xr.DataArray(\n",
    "            data   = BCLP_writeCLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'Pa',\n",
    "                'LongName'  : 'Pressure of convective threshold'\n",
    "                }\n",
    "            ),\n",
    "    'TDEF': xr.DataArray(\n",
    "            data   = TDEF_writeCLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'K',\n",
    "                'LongName'  : 'Potential temperature deficit needed to initiate convection'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_H': xr.DataArray(\n",
    "            data   = TRAN_H_writeCLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'm',\n",
    "                'LongName'  : 'Energy transition height'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_P': xr.DataArray(\n",
    "            data   = TRAN_P_writeCLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'Pa',\n",
    "                'LongName'  : 'Energy transition pressure'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_T': xr.DataArray(\n",
    "            data   = TRAN_T_writeCLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'K',\n",
    "                'LongName'  : 'Energy transition temperature'\n",
    "                }\n",
    "            ),\n",
    "    'SHDEF_M': xr.DataArray(\n",
    "            data   = SHDEF_M_writeCLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'J/m2',\n",
    "                'LongName'  : 'Sensible heat deficit of mixed layer'\n",
    "                }\n",
    "            ),\n",
    "    'LHDEF_M': xr.DataArray(\n",
    "            data   = LHDEF_M_writeCLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'J/m2',\n",
    "                'LongName'  : 'Latent heat deficit of mixed layer'\n",
    "                }\n",
    "            ),\n",
    "    'EADV_M': xr.DataArray(\n",
    "            data   = EADV_M_writeCLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : '-',\n",
    "                'LongName'  : 'Energy advantage of mixed layer'\n",
    "                }\n",
    "            )\n",
    "    } )\n",
    "\n",
    "# -------------------\n",
    "# Save to netCDF \n",
    "# -------------------\n",
    "\n",
    "savePath = '/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/processed_data/HCFvariables-CAM6CLM5_'+yearString+'.nc'\n",
    "HCF_ds_CLM5.to_netcdf(savePath, mode='w')\n",
    "print('Saved file %s' % savePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file /glade/work/mdfowler/scripts/Coupling_CAM6CLM5/processed_data/HCFvariables-CAM5CLM5_1989.nc\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Create xr dataset from variables above \n",
    "# ---------------------------------------\n",
    "\n",
    "# First set missing values to -9999\n",
    "missingValue  = -9999\n",
    "\n",
    "TBM_writeCAM5CLM5     = np.copy(TBM_CAM5CLM5)\n",
    "BCLH_writeCAM5CLM5    = np.copy(BCLH_CAM5CLM5)\n",
    "BCLP_writeCAM5CLM5    = np.copy(BCLP_CAM5CLM5)\n",
    "TDEF_writeCAM5CLM5    = np.copy(TDEF_CAM5CLM5)\n",
    "TRAN_H_writeCAM5CLM5  = np.copy(TRAN_H_CAM5CLM5)\n",
    "TRAN_P_writeCAM5CLM5  = np.copy(TRAN_P_CAM5CLM5)\n",
    "TRAN_T_writeCAM5CLM5  = np.copy(TRAN_T_CAM5CLM5)\n",
    "SHDEF_M_writeCAM5CLM5 = np.copy(SHDEF_M_CAM5CLM5)\n",
    "LHDEF_M_writeCAM5CLM5 = np.copy(LHDEF_M_CAM5CLM5)\n",
    "EADV_M_writeCAM5CLM5  = np.copy(EADV_M_CAM5CLM5)\n",
    "\n",
    "TBM_writeCAM5CLM5    [np.isnan(TBM_CAM5CLM5)    ==True] = missingValue\n",
    "BCLH_writeCAM5CLM5   [np.isnan(BCLH_CAM5CLM5)   ==True] = missingValue\n",
    "BCLP_writeCAM5CLM5   [np.isnan(BCLP_CAM5CLM5)   ==True] = missingValue\n",
    "TDEF_writeCAM5CLM5   [np.isnan(TDEF_CAM5CLM5)   ==True] = missingValue\n",
    "TRAN_H_writeCAM5CLM5 [np.isnan(TRAN_H_CAM5CLM5) ==True] = missingValue\n",
    "TRAN_P_writeCAM5CLM5 [np.isnan(TRAN_P_CAM5CLM5) ==True] = missingValue\n",
    "TRAN_T_writeCAM5CLM5 [np.isnan(TRAN_T_CAM5CLM5) ==True] = missingValue\n",
    "SHDEF_M_writeCAM5CLM5[np.isnan(SHDEF_M_CAM5CLM5)==True] = missingValue\n",
    "LHDEF_M_writeCAM5CLM5[np.isnan(LHDEF_M_CAM5CLM5)==True] = missingValue\n",
    "EADV_M_writeCAM5CLM5 [np.isnan(EADV_M_CAM5CLM5) ==True] = missingValue\n",
    " \n",
    "HCF_ds_CAM5CLM5 = xr.Dataset({\n",
    "    'TBM': xr.DataArray(\n",
    "                data   = TBM_writeCAM5CLM5,   # enter data here\n",
    "                dims   = ['time','lat','lon'],\n",
    "                coords = {'time': ds_utc12_CAM5CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "                attrs  = {\n",
    "                    '_FillValue': missingValue,\n",
    "                    'units'     : 'K',\n",
    "                    'LongName'  : 'Buoyant mixing potential temperature (convective threshold)'\n",
    "                    }\n",
    "                ),\n",
    "    'BCLH': xr.DataArray(\n",
    "                data   = BCLH_writeCAM5CLM5,   # enter data here\n",
    "                dims   = ['time','lat','lon'],\n",
    "                coords = {'time': ds_utc12_CAM5CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "                attrs  = {\n",
    "                    '_FillValue': missingValue,\n",
    "                    'units'     : 'm',\n",
    "                    'LongName'  : 'Height above ground of convective threshold'\n",
    "                    }\n",
    "                ),\n",
    "    'BCLP': xr.DataArray(\n",
    "            data   = BCLP_writeCAM5CLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CAM5CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'Pa',\n",
    "                'LongName'  : 'Pressure of convective threshold'\n",
    "                }\n",
    "            ),\n",
    "    'TDEF': xr.DataArray(\n",
    "            data   = TDEF_writeCAM5CLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CAM5CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'K',\n",
    "                'LongName'  : 'Potential temperature deficit needed to initiate convection'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_H': xr.DataArray(\n",
    "            data   = TRAN_H_writeCAM5CLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CAM5CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'm',\n",
    "                'LongName'  : 'Energy transition height'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_P': xr.DataArray(\n",
    "            data   = TRAN_P_writeCAM5CLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CAM5CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'Pa',\n",
    "                'LongName'  : 'Energy transition pressure'\n",
    "                }\n",
    "            ),\n",
    "    'TRAN_T': xr.DataArray(\n",
    "            data   = TRAN_T_writeCAM5CLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CAM5CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'K',\n",
    "                'LongName'  : 'Energy transition temperature'\n",
    "                }\n",
    "            ),\n",
    "    'SHDEF_M': xr.DataArray(\n",
    "            data   = SHDEF_M_writeCAM5CLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CAM5CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'J/m2',\n",
    "                'LongName'  : 'Sensible heat deficit of mixed layer'\n",
    "                }\n",
    "            ),\n",
    "    'LHDEF_M': xr.DataArray(\n",
    "            data   = LHDEF_M_writeCAM5CLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CAM5CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : 'J/m2',\n",
    "                'LongName'  : 'Latent heat deficit of mixed layer'\n",
    "                }\n",
    "            ),\n",
    "    'EADV_M': xr.DataArray(\n",
    "            data   = EADV_M_writeCAM5CLM5,   # enter data here\n",
    "            dims   = ['time','lat','lon'],\n",
    "            coords = {'time': ds_utc12_CAM5CLM5.time.values, 'lat':lat, 'lon': lon},\n",
    "            attrs  = {\n",
    "                '_FillValue': missingValue,\n",
    "                'units'     : '-',\n",
    "                'LongName'  : 'Energy advantage of mixed layer'\n",
    "                }\n",
    "            )\n",
    "    } )\n",
    "\n",
    "# -------------------\n",
    "# Save to netCDF \n",
    "# -------------------\n",
    "\n",
    "savePath = '/glade/work/mdfowler/scripts/Coupling_CAM6CLM5/processed_data/HCFvariables-CAM5CLM5_'+yearString+'.nc'\n",
    "HCF_ds_CAM5CLM5.to_netcdf(savePath, mode='w')\n",
    "print('Saved file %s' % savePath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
